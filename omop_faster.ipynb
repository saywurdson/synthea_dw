{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = pd.read_csv('/workspaces/synthea_dw/omop/seeds/CONCEPT.csv', delimiter='\\t', low_memory=False)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_concept_id(\n",
    "        concept, concept_codes=None, \n",
    "        concept_names=None, vocabulary_ids=None, \n",
    "        domain_ids=None, concept_class_ids=None, \n",
    "        invalid_reason=False, standard_concept=None\n",
    "    ):\n",
    "    query_components = []\n",
    "\n",
    "    if concept_codes:\n",
    "        query_components.append(f\"concept_code in @concept_codes\")\n",
    "    if concept_names:\n",
    "        query_components.append(f\"concept_name in @concept_names\")\n",
    "    if vocabulary_ids:\n",
    "        query_components.append(f\"vocabulary_id in @vocabulary_ids\")\n",
    "    if not invalid_reason:\n",
    "        query_components.append(f\"invalid_reason.isnull()\")\n",
    "    if standard_concept:\n",
    "        query_components.append(f\"standard_concept == @standard_concept\")\n",
    "    if domain_ids:\n",
    "        query_components.append(f\"domain_id in @domain_ids\")\n",
    "    if concept_class_ids:\n",
    "        query_components.append(f\"concept_class_id in @concept_class_ids\")\n",
    "\n",
    "    query = \" and \".join(query_components)\n",
    "    \n",
    "    concept_rows = concept.query(query)['concept_id'] if query else concept['concept_id']\n",
    "    \n",
    "    return int(concept_rows.iloc[0]) if not concept_rows.empty else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>gender_concept_id</th>\n",
       "      <th>year_of_birth</th>\n",
       "      <th>month_of_birth</th>\n",
       "      <th>day_of_birth</th>\n",
       "      <th>birth_datetime</th>\n",
       "      <th>race_concept_id</th>\n",
       "      <th>ethnicity_concept_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>care_site_id</th>\n",
       "      <th>person_source_value</th>\n",
       "      <th>gender_source_value</th>\n",
       "      <th>gender_source_concept_id</th>\n",
       "      <th>race_source_value</th>\n",
       "      <th>race_source_concept_id</th>\n",
       "      <th>ethnicity_source_value</th>\n",
       "      <th>ethnicity_source_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7a82833f-fae1-d69a-2cbf-69279dac746f</td>\n",
       "      <td>8532</td>\n",
       "      <td>1967</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1967-05-20 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7a82833f-fae1-d69a-2cbf-69279dac746f</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7a82833f-fae1-d69a-2cbf-69279dac746f</td>\n",
       "      <td>F</td>\n",
       "      <td>8532</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408a95f4-02aa-3003-2f09-0241ac3343fb</td>\n",
       "      <td>8532</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1958-01-08 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>408a95f4-02aa-3003-2f09-0241ac3343fb</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>408a95f4-02aa-3003-2f09-0241ac3343fb</td>\n",
       "      <td>F</td>\n",
       "      <td>8532</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>8507</td>\n",
       "      <td>1969</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>1969-11-16 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>M</td>\n",
       "      <td>8507</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c95d085d-2249-b616-7668-88cc9a0c11bd</td>\n",
       "      <td>8532</td>\n",
       "      <td>1958</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1958-08-17 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c95d085d-2249-b616-7668-88cc9a0c11bd</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>c95d085d-2249-b616-7668-88cc9a0c11bd</td>\n",
       "      <td>F</td>\n",
       "      <td>8532</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4390395b-5a78-2005-80b7-5ebd62b595c9</td>\n",
       "      <td>8507</td>\n",
       "      <td>1944</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1944-08-02 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4390395b-5a78-2005-80b7-5ebd62b595c9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4390395b-5a78-2005-80b7-5ebd62b595c9</td>\n",
       "      <td>M</td>\n",
       "      <td>8507</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              person_id  gender_concept_id  year_of_birth  month_of_birth  day_of_birth       birth_datetime  race_concept_id  ethnicity_concept_id                           location_id provider_id care_site_id                   person_source_value gender_source_value  gender_source_concept_id race_source_value  race_source_concept_id ethnicity_source_value  ethnicity_source_concept_id\n",
       "1  7a82833f-fae1-d69a-2cbf-69279dac746f               8532           1967               5            20  1967-05-20 00:00:00                0                     0  7a82833f-fae1-d69a-2cbf-69279dac746f        <NA>         <NA>  7a82833f-fae1-d69a-2cbf-69279dac746f                   F                      8532              None                       0                   None                            0\n",
       "4  408a95f4-02aa-3003-2f09-0241ac3343fb               8532           1958               1             8  1958-01-08 00:00:00                0                     0  408a95f4-02aa-3003-2f09-0241ac3343fb        <NA>         <NA>  408a95f4-02aa-3003-2f09-0241ac3343fb                   F                      8532              None                       0                   None                            0\n",
       "9  7a7b7fba-a005-3736-91ef-218a0d2824c5               8507           1969              11            16  1969-11-16 00:00:00                0                     0  7a7b7fba-a005-3736-91ef-218a0d2824c5        <NA>         <NA>  7a7b7fba-a005-3736-91ef-218a0d2824c5                   M                      8507              None                       0                   None                            0\n",
       "7  c95d085d-2249-b616-7668-88cc9a0c11bd               8532           1958               8            17  1958-08-17 00:00:00                0                     0  c95d085d-2249-b616-7668-88cc9a0c11bd        <NA>         <NA>  c95d085d-2249-b616-7668-88cc9a0c11bd                   F                      8532              None                       0                   None                            0\n",
       "6  4390395b-5a78-2005-80b7-5ebd62b595c9               8507           1944               8             2  1944-08-02 00:00:00                0                     0  4390395b-5a78-2005-80b7-5ebd62b595c9        <NA>         <NA>  4390395b-5a78-2005-80b7-5ebd62b595c9                   M                      8507              None                       0                   None                            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def person(filepaths, concept, max_workers=10):\n",
    "    person_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "\n",
    "        # Extracting the year, month, and day of birth\n",
    "        birth_year = int(data['birthDate'].split('-')[0])\n",
    "        birth_month = int(data['birthDate'].split('-')[1])\n",
    "        birth_day = int(data['birthDate'].split('-')[2])\n",
    "        birth_datetime = datetime.fromisoformat(data['birthDate']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        race_code, ethnicity_code, gender_source_value = None, None, None\n",
    "        for ext in data.get('extension', []):\n",
    "            if ext.get('url') == 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-race':\n",
    "                race_code = ext['valueCoding']['display'] if 'valueCoding' in ext else None\n",
    "            elif ext.get('url') == 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-ethnicity':\n",
    "                ethnicity_code = ext['valueCoding']['display'] if 'valueCoding' in ext else None\n",
    "            elif ext.get('url') == 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-birthsex':\n",
    "                gender_source_value = ext.get('valueCode')\n",
    "\n",
    "        race_concept_id = find_concept_id(concept, concept_names=[race_code], vocabulary_ids=['Race'])\n",
    "        ethnicity_concept_id = find_concept_id(concept, concept_names=[ethnicity_code], vocabulary_ids=['Ethnicity'])\n",
    "        gender_concept_id = find_concept_id(concept, concept_codes=[gender_source_value], vocabulary_ids=['Gender'])\n",
    "\n",
    "        return {\n",
    "            'person_id': data['id'],\n",
    "            'gender_concept_id': gender_concept_id,\n",
    "            'year_of_birth': birth_year,\n",
    "            'month_of_birth': birth_month,\n",
    "            'day_of_birth': birth_day,\n",
    "            'birth_datetime': birth_datetime,\n",
    "            'race_concept_id': race_concept_id,\n",
    "            'ethnicity_concept_id': ethnicity_concept_id,\n",
    "            'location_id': data['id'],\n",
    "            'provider_id': pd.NA,\n",
    "            'care_site_id': pd.NA,\n",
    "            'person_source_value': data['id'],\n",
    "            'gender_source_value': gender_source_value,\n",
    "            'gender_source_concept_id': gender_concept_id,\n",
    "            'race_source_value': race_code,\n",
    "            'race_source_concept_id': race_concept_id,\n",
    "            'ethnicity_source_value': ethnicity_code,\n",
    "            'ethnicity_source_concept_id': ethnicity_concept_id\n",
    "        }\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    person_rows.append(result)\n",
    "\n",
    "    person = pd.DataFrame(person_rows).drop_duplicates()\n",
    "\n",
    "    return person\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Patient.ndjson']\n",
    "person_df = person(filepaths, concept)\n",
    "person_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>visit_concept_id</th>\n",
       "      <th>visit_start_date</th>\n",
       "      <th>visit_start_datetime</th>\n",
       "      <th>visit_end_date</th>\n",
       "      <th>visit_end_datetime</th>\n",
       "      <th>visit_type_concept_id</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>care_site_id</th>\n",
       "      <th>visit_source_value</th>\n",
       "      <th>visit_source_concept_id</th>\n",
       "      <th>admitted_from_concept_id</th>\n",
       "      <th>admitted_from_source_value</th>\n",
       "      <th>discharged_to_concept_id</th>\n",
       "      <th>discharged_to_source_value</th>\n",
       "      <th>preceding_visit_occurrence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0e87aa43-3404-0c15-d9ab-b5df454e400e</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>2019-04-13 05:06:03+00:00</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>2019-04-13 08:13:03+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>299bc447-29c4-3c98-948b-ea0891c97d89</td>\n",
       "      <td>497f39dd-280e-3d58-af5b-c5e3a3a09b10</td>\n",
       "      <td>AMB</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>5c01c2f4-1cb3-6ff2-961f-6378ab7ac778</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>2016-11-29 00:29:03+00:00</td>\n",
       "      <td>2016-11-29</td>\n",
       "      <td>2016-11-29 02:54:03+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>299bc447-29c4-3c98-948b-ea0891c97d89</td>\n",
       "      <td>497f39dd-280e-3d58-af5b-c5e3a3a09b10</td>\n",
       "      <td>AMB</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>ec57fabd-e567-c6b8-ab2f-5c2482e206d1</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-02-01 20:17:03+00:00</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>2020-02-01 20:32:03+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>299bc447-29c4-3c98-948b-ea0891c97d89</td>\n",
       "      <td>497f39dd-280e-3d58-af5b-c5e3a3a09b10</td>\n",
       "      <td>AMB</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>9c9b717b-42fc-f67c-a898-9417e2a96c71</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>2018-11-24 17:40:03+00:00</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>2018-11-24 20:47:03+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>299bc447-29c4-3c98-948b-ea0891c97d89</td>\n",
       "      <td>497f39dd-280e-3d58-af5b-c5e3a3a09b10</td>\n",
       "      <td>AMB</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>3bfa4723-7b69-853f-9e1e-18408050bc81</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>2018-11-02 16:52:03+00:00</td>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>2018-11-02 18:53:03+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>299bc447-29c4-3c98-948b-ea0891c97d89</td>\n",
       "      <td>497f39dd-280e-3d58-af5b-c5e3a3a09b10</td>\n",
       "      <td>AMB</td>\n",
       "      <td>9202.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      visit_occurrence_id                             person_id  visit_concept_id visit_start_date      visit_start_datetime visit_end_date        visit_end_datetime  visit_type_concept_id                           provider_id                          care_site_id visit_source_value  visit_source_concept_id admitted_from_concept_id admitted_from_source_value discharged_to_concept_id discharged_to_source_value preceding_visit_occurrence_id\n",
       "798  0e87aa43-3404-0c15-d9ab-b5df454e400e  7a7b7fba-a005-3736-91ef-218a0d2824c5            9202.0       2019-04-13 2019-04-13 05:06:03+00:00     2019-04-13 2019-04-13 08:13:03+00:00                  32817  299bc447-29c4-3c98-948b-ea0891c97d89  497f39dd-280e-3d58-af5b-c5e3a3a09b10                AMB                   9202.0                     <NA>                       None                     <NA>                       None                          <NA>\n",
       "573  5c01c2f4-1cb3-6ff2-961f-6378ab7ac778  7a7b7fba-a005-3736-91ef-218a0d2824c5            9202.0       2016-11-29 2016-11-29 00:29:03+00:00     2016-11-29 2016-11-29 02:54:03+00:00                  32817  299bc447-29c4-3c98-948b-ea0891c97d89  497f39dd-280e-3d58-af5b-c5e3a3a09b10                AMB                   9202.0                     <NA>                       None                     <NA>                       None                          <NA>\n",
       "921  ec57fabd-e567-c6b8-ab2f-5c2482e206d1  7a7b7fba-a005-3736-91ef-218a0d2824c5            9202.0       2020-02-01 2020-02-01 20:17:03+00:00     2020-02-01 2020-02-01 20:32:03+00:00                  32817  299bc447-29c4-3c98-948b-ea0891c97d89  497f39dd-280e-3d58-af5b-c5e3a3a09b10                AMB                   9202.0                     <NA>                       None                     <NA>                       None                          <NA>\n",
       "796  9c9b717b-42fc-f67c-a898-9417e2a96c71  7a7b7fba-a005-3736-91ef-218a0d2824c5            9202.0       2018-11-24 2018-11-24 17:40:03+00:00     2018-11-24 2018-11-24 20:47:03+00:00                  32817  299bc447-29c4-3c98-948b-ea0891c97d89  497f39dd-280e-3d58-af5b-c5e3a3a09b10                AMB                   9202.0                     <NA>                       None                     <NA>                       None                          <NA>\n",
       "762  3bfa4723-7b69-853f-9e1e-18408050bc81  7a7b7fba-a005-3736-91ef-218a0d2824c5            9202.0       2018-11-02 2018-11-02 16:52:03+00:00     2018-11-02 2018-11-02 18:53:03+00:00                  32817  299bc447-29c4-3c98-948b-ea0891c97d89  497f39dd-280e-3d58-af5b-c5e3a3a09b10                AMB                   9202.0                     <NA>                       None                     <NA>                       None                          <NA>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def visit_occurrence(filepaths, concept, max_workers=10):\n",
    "    visit_occurrences = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "        person_id = data['subject']['reference'].split('/')[-1]\n",
    "\n",
    "        if resource_type == 'CareTeam':\n",
    "            provider_id, care_site_id = None, None\n",
    "            for participant in data.get('participant', []):\n",
    "                for role in participant.get('role', []):\n",
    "                    for coding in role.get('coding', []):\n",
    "                        if coding.get('code') == '116154003':\n",
    "                            person_id = participant['member']['reference'].split('/')[-1]\n",
    "                        elif coding.get('code') == '223366009': \n",
    "                            provider_id = participant['member']['reference'].split('/')[-1]\n",
    "                        elif coding.get('code') == '224891009': \n",
    "                            care_site_id = participant['member']['reference'].split('/')[-1]\n",
    "\n",
    "            visit_occurrence = {\n",
    "                'visit_occurrence_id': data['encounter']['reference'].split('/')[-1],\n",
    "                'person_id': person_id,\n",
    "                'visit_concept_id': 9201,\n",
    "                'visit_start_date': datetime.strptime(data['period']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                'visit_start_datetime': datetime.fromisoformat(data['period']['start']),\n",
    "                'visit_end_date': datetime.strptime(data['period']['end'].split('T')[0], '%Y-%m-%d').date() if 'end' in data['period'] else None,\n",
    "                'visit_end_datetime': datetime.fromisoformat(data['period']['end']) if 'end' in data['period'] else None,\n",
    "                'visit_type_concept_id': 32817,\n",
    "                'provider_id': provider_id,\n",
    "                'care_site_id': care_site_id,\n",
    "                'visit_source_value': 'IP',\n",
    "                'visit_source_concept_id': 9201,\n",
    "                'admitted_from_concept_id': pd.NA,\n",
    "                'admitted_from_source_value': None,\n",
    "                'discharged_to_concept_id': pd.NA,\n",
    "                'discharged_to_source_value': None,\n",
    "                'preceding_visit_occurrence_id': pd.NA\n",
    "            }\n",
    "\n",
    "        elif resource_type == 'Encounter':\n",
    "            visit_class_code = data['class']['code'] if 'class' in data else None\n",
    "            visit_concept_id_map = {'IMP': 9201, 'EMER': 9203, 'AMB': 9202}\n",
    "            visit_concept_id = visit_concept_id_map.get(visit_class_code, None)\n",
    "            provider_id = data['participant'][0]['individual']['reference'].split('/')[-1] if 'participant' in data and 'individual' in data['participant'][0] else None\n",
    "            care_site_id = data['serviceProvider']['reference'].split('/')[-1] if 'serviceProvider' in data else None\n",
    "\n",
    "            visit_occurrence = {\n",
    "                'visit_occurrence_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'visit_concept_id': visit_concept_id,\n",
    "                'visit_start_date': datetime.strptime(data['period']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                'visit_start_datetime': datetime.fromisoformat(data['period']['start']),\n",
    "                'visit_end_date': datetime.strptime(data['period']['end'].split('T')[0], '%Y-%m-%d').date() if 'end' in data['period'] else None,\n",
    "                'visit_end_datetime': datetime.fromisoformat(data['period']['end']) if 'end' in data['period'] else None,\n",
    "                'visit_type_concept_id': 32817,\n",
    "                'provider_id': provider_id,\n",
    "                'care_site_id': care_site_id,\n",
    "                'visit_source_value': visit_class_code,\n",
    "                'visit_source_concept_id': visit_concept_id,\n",
    "                'admitted_from_concept_id': pd.NA,\n",
    "                'admitted_from_source_value': None,\n",
    "                'discharged_to_concept_id': pd.NA,\n",
    "                'discharged_to_source_value': None,\n",
    "                'preceding_visit_occurrence_id': pd.NA\n",
    "            }\n",
    "\n",
    "        return visit_occurrence\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                visit_occurrences.append(future.result())\n",
    "    \n",
    "    visit_occurrence = pd.DataFrame(visit_occurrences).drop_duplicates()\n",
    "\n",
    "    return visit_occurrence\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/CareTeam.ndjson', '/workspaces/synthea_dw/data/fhir/Encounter.ndjson']\n",
    "visit_occurrence_df = visit_occurrence(filepaths, concept)\n",
    "visit_occurrence_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_occurrence_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>condition_concept_id</th>\n",
       "      <th>condition_start_date</th>\n",
       "      <th>condition_start_datetime</th>\n",
       "      <th>condition_end_date</th>\n",
       "      <th>condition_end_datetime</th>\n",
       "      <th>condition_type_concept_id</th>\n",
       "      <th>condition_status_concept_id</th>\n",
       "      <th>stop_reason</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>visit_detail_id</th>\n",
       "      <th>condition_source_concept_id</th>\n",
       "      <th>condition_status_source_value</th>\n",
       "      <th>condition_source_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7196</th>\n",
       "      <td>32c73b65-827c-fd2c-31d2-d3559df734de</td>\n",
       "      <td>7a82833f-fae1-d69a-2cbf-69279dac746f</td>\n",
       "      <td>4309238</td>\n",
       "      <td>2014-12-13</td>\n",
       "      <td>2014-12-13 02:39:06+00:00</td>\n",
       "      <td>2015-02-21</td>\n",
       "      <td>2015-02-21 02:29:28+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>37109701</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>528ff2b6-d6ea-2ec2-cde4-b84ac955067e</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4309238</td>\n",
       "      <td>422650009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>490f2ba1-7578-c902-3cb9-7ac8230d6064</td>\n",
       "      <td>7a82833f-fae1-d69a-2cbf-69279dac746f</td>\n",
       "      <td>4172829</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>2018-05-26 01:46:00+00:00</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>2018-05-26 02:25:44+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4172829</td>\n",
       "      <td>423315002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>8d20c824-d2c7-47a4-8d59-aab806ef4fa8</td>\n",
       "      <td>7a82833f-fae1-d69a-2cbf-69279dac746f</td>\n",
       "      <td>4251306</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>2020-10-10 02:35:15+00:00</td>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>2020-11-21 02:41:47+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>37109701</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>82575e97-c41d-fd32-a16a-cefd2ef33041</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4251306</td>\n",
       "      <td>73595000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>76f86b9a-68b4-f6af-b1c8-8258484c6509</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>4309238</td>\n",
       "      <td>2016-07-24</td>\n",
       "      <td>2016-07-24 12:59:27+00:00</td>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>2017-02-26 12:46:48+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>37109701</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>cfd8a830-512b-39f3-54f2-c229eac60284</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4309238</td>\n",
       "      <td>422650009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>1b7138a2-6d4b-b769-8f0a-825fabc06ecb</td>\n",
       "      <td>a5a02d31-a93c-7b72-7e1c-a9cbfa64874d</td>\n",
       "      <td>436940</td>\n",
       "      <td>2011-03-02</td>\n",
       "      <td>2011-03-02 08:52:48+00:00</td>\n",
       "      <td>2011-03-02</td>\n",
       "      <td>2011-03-02 09:45:56+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>436940</td>\n",
       "      <td>237602007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   condition_occurrence_id                             person_id  condition_concept_id condition_start_date  condition_start_datetime condition_end_date    condition_end_datetime  condition_type_concept_id condition_status_concept_id stop_reason provider_id                   visit_occurrence_id visit_detail_id  condition_source_concept_id condition_status_source_value condition_source_value\n",
       "7196  32c73b65-827c-fd2c-31d2-d3559df734de  7a82833f-fae1-d69a-2cbf-69279dac746f               4309238           2014-12-13 2014-12-13 02:39:06+00:00         2015-02-21 2015-02-21 02:29:28+00:00                      32817                    37109701        None        <NA>  528ff2b6-d6ea-2ec2-cde4-b84ac955067e            <NA>                      4309238                     422650009                    NaN\n",
       "2470  490f2ba1-7578-c902-3cb9-7ac8230d6064  7a82833f-fae1-d69a-2cbf-69279dac746f               4172829           2018-05-26 2018-05-26 01:46:00+00:00         2018-05-26 2018-05-26 02:25:44+00:00                      32817                        <NA>        None        <NA>                                  None            <NA>                      4172829                     423315002                    NaN\n",
       "7373  8d20c824-d2c7-47a4-8d59-aab806ef4fa8  7a82833f-fae1-d69a-2cbf-69279dac746f               4251306           2020-10-10 2020-10-10 02:35:15+00:00         2020-11-21 2020-11-21 02:41:47+00:00                      32817                    37109701        None        <NA>  82575e97-c41d-fd32-a16a-cefd2ef33041            <NA>                      4251306                      73595000                    NaN\n",
       "7512  76f86b9a-68b4-f6af-b1c8-8258484c6509  7a7b7fba-a005-3736-91ef-218a0d2824c5               4309238           2016-07-24 2016-07-24 12:59:27+00:00         2017-02-26 2017-02-26 12:46:48+00:00                      32817                    37109701        None        <NA>  cfd8a830-512b-39f3-54f2-c229eac60284            <NA>                      4309238                     422650009                    NaN\n",
       "1230  1b7138a2-6d4b-b769-8f0a-825fabc06ecb  a5a02d31-a93c-7b72-7e1c-a9cbfa64874d                436940           2011-03-02 2011-03-02 08:52:48+00:00         2011-03-02 2011-03-02 09:45:56+00:00                      32817                        <NA>        None        <NA>                                  None            <NA>                       436940                     237602007                    NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def condition_occurrence(filepaths, concept, max_workers=10):\n",
    "    condition_occurrences = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "        conditions = []\n",
    "\n",
    "        if resource_type == 'AllergyIntolerance':\n",
    "            if data['code']['coding'][0]['code'] == '419199007':\n",
    "                return []\n",
    "\n",
    "            for reaction in data.get('reaction', []):\n",
    "                for manifestation in reaction.get('manifestation', []):\n",
    "                    conditions.append({\n",
    "                        'condition_occurrence_id': data['id'],\n",
    "                        'person_id': data['patient']['reference'].split('/')[-1],\n",
    "                        'condition_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[manifestation['coding'][0]['code']], \n",
    "                            vocabulary_ids=['SNOMED'], \n",
    "                            domain_ids=['Condition'], \n",
    "                            invalid_reason=False, \n",
    "                            standard_concept='S'\n",
    "                        ),\n",
    "                        'condition_start_date': datetime.strptime(data['recordedDate'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                        'condition_start_datetime': datetime.fromisoformat(data['recordedDate']),\n",
    "                        'condition_end_date': None,\n",
    "                        'condition_end_datetime': None,\n",
    "                        'condition_type_concept_id': 32817,\n",
    "                        'condition_status_concept_id': pd.NA,\n",
    "                        'stop_reason': None,\n",
    "                        'provider_id': pd.NA,\n",
    "                        'visit_occurrence_id': pd.NA,\n",
    "                        'visit_detail_id': pd.NA,\n",
    "                        'condition_source_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[manifestation['coding'][0]['code']], \n",
    "                            vocabulary_ids=['SNOMED'], \n",
    "                            domain_ids=['Condition'], \n",
    "                            invalid_reason=True\n",
    "                        ),\n",
    "                        'condition_status_source_value': manifestation['coding'][0]['code']\n",
    "                    })\n",
    "\n",
    "        elif resource_type == 'CareTeam':\n",
    "            if 'reasonCode' in data:\n",
    "                person_id = None\n",
    "                provider_id = None\n",
    "                for participant in data.get('participant', []):\n",
    "                    for role in participant.get('role', []):\n",
    "                        for coding in role.get('coding', []):\n",
    "                            if coding.get('code') == '116154003':\n",
    "                                person_id = participant['member']['reference'].split('/')[-1]\n",
    "                            elif coding.get('code') == '223366009':\n",
    "                                provider_id = participant['member']['reference'].split('/')[-1]\n",
    "\n",
    "                if person_id:\n",
    "                    for reasonCode in data['reasonCode']:\n",
    "                        for coding in reasonCode.get('coding', []):\n",
    "                            condition_occurrence = {\n",
    "                                'condition_occurrence_id': data['id'],\n",
    "                                'person_id': person_id,\n",
    "                                'condition_concept_id': find_concept_id(\n",
    "                                    concept, \n",
    "                                    concept_codes=[coding['code']], \n",
    "                                    vocabulary_ids=['SNOMED'], \n",
    "                                    domain_ids=['Condition'],\n",
    "                                    invalid_reason=False, \n",
    "                                    standard_concept='S'\n",
    "                                ),\n",
    "                                'condition_start_date': datetime.strptime(data['period']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                                'condition_start_datetime': datetime.fromisoformat(data['period']['start']),\n",
    "                                'condition_end_date': None,\n",
    "                                'condition_end_datetime': None,\n",
    "                                'condition_type_concept_id': 32817,\n",
    "                                'condition_status_concept_id': pd.NA,\n",
    "                                'stop_reason': None,\n",
    "                                'provider_id': provider_id,\n",
    "                                'visit_occurrence_id': data['encounter']['reference'].split('/')[-1],\n",
    "                                'visit_detail_id': pd.NA,\n",
    "                                'condition_source_value': coding['code'],\n",
    "                                'condition_source_concept_id': find_concept_id(\n",
    "                                    concept, \n",
    "                                    concept_codes=[coding['code']], \n",
    "                                    vocabulary_ids=['SNOMED'], \n",
    "                                    domain_ids=['Condition']\n",
    "                                ),\n",
    "                                'condition_status_source_value': None\n",
    "                            }\n",
    "                            conditions.append(condition_occurrence)\n",
    "\n",
    "        elif resource_type == 'Claim':\n",
    "            if any(coding['code'] in ['professional', 'institutional'] for coding in data['type']['coding']):\n",
    "                for diagnosis in data.get('diagnosis', []):\n",
    "                    condition_ref = diagnosis['diagnosisReference']['reference']\n",
    "                    condition_id = condition_ref.split('/')[-1]\n",
    "\n",
    "                    for item in data.get('item', []):\n",
    "                        if 'productOrService' in item and 'coding' in item['productOrService']:\n",
    "                            for coding in item['productOrService']['coding']:\n",
    "                                condition_occurrence = {\n",
    "                                    'condition_occurrence_id': condition_id,\n",
    "                                    'person_id': data['patient']['reference'].split('/')[-1],\n",
    "                                    'condition_concept_id': find_concept_id(\n",
    "                                        concept, \n",
    "                                        concept_codes=[coding['code']], \n",
    "                                        vocabulary_ids=['SNOMED'], \n",
    "                                        domain_ids=['Condition'], \n",
    "                                        invalid_reason=False, \n",
    "                                        standard_concept='S'\n",
    "                                    ),\n",
    "                                    'condition_start_date': datetime.strptime(data['billablePeriod']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                                    'condition_start_datetime': datetime.fromisoformat(data['billablePeriod']['start']),\n",
    "                                    'condition_end_date': datetime.strptime(data['billablePeriod']['end'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                                    'condition_end_datetime': datetime.fromisoformat(data['billablePeriod']['end']),\n",
    "                                    'condition_type_concept_id': 32817,\n",
    "                                    'condition_status_concept_id': pd.NA,\n",
    "                                    'stop_reason': None,\n",
    "                                    'provider_id': pd.NA,\n",
    "                                    'visit_occurrence_id': item['encounter'][0]['reference'].split('/')[-1] if 'encounter' in item else None,\n",
    "                                    'visit_detail_id': pd.NA,\n",
    "                                    'condition_source_concept_id': find_concept_id(\n",
    "                                        concept, \n",
    "                                        concept_codes=[coding['code']], \n",
    "                                        vocabulary_ids=['SNOMED'], \n",
    "                                        domain_ids=['Condition']\n",
    "                                    ),\n",
    "                                    'condition_status_source_value': coding['code']\n",
    "                                }\n",
    "                                conditions.append(condition_occurrence)\n",
    "\n",
    "        elif resource_type == 'Condition':\n",
    "            person_id = data['subject']['reference'].split('/')[-1]\n",
    "            condition_code = data['code']['coding'][0]['code']\n",
    "            clinical_status_code = data['clinicalStatus']['coding'][0]['code']\n",
    "\n",
    "            condition_status_concept_id = 37109701 if clinical_status_code == 'resolved' else 9181 if clinical_status_code == 'active' else pd.NA\n",
    "            condition_abatement_datetime = datetime.fromisoformat(data['abatementDateTime']) if 'abatementDateTime' in data else None\n",
    "\n",
    "            condition_occurrence = {\n",
    "                'condition_occurrence_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'condition_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[condition_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Condition'], \n",
    "                    invalid_reason=False, \n",
    "                    standard_concept='S'\n",
    "                ),\n",
    "                'condition_start_date': datetime.strptime(data['onsetDateTime'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                'condition_start_datetime': datetime.fromisoformat(data['onsetDateTime']),\n",
    "                'condition_end_date': condition_abatement_datetime.date() if condition_abatement_datetime else None,\n",
    "                'condition_end_datetime': condition_abatement_datetime,\n",
    "                'condition_type_concept_id': 32817,\n",
    "                'condition_status_concept_id': condition_status_concept_id,\n",
    "                'stop_reason': None,\n",
    "                'provider_id': pd.NA,\n",
    "                'visit_occurrence_id': data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None,\n",
    "                'visit_detail_id': pd.NA,\n",
    "                'condition_source_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[condition_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Condition']\n",
    "                ),\n",
    "                'condition_status_source_value': condition_code\n",
    "            }\n",
    "            conditions.append(condition_occurrence)\n",
    "\n",
    "        return conditions\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "            for future in as_completed(future_to_line):\n",
    "                condition_occurrences.extend(future.result())\n",
    "\n",
    "    condition_occurrence = pd.DataFrame(condition_occurrences).drop_duplicates()\n",
    "    condition_occurrence = condition_occurrence[condition_occurrence['condition_source_concept_id'] != 0]\n",
    "\n",
    "    return condition_occurrence\n",
    "\n",
    "filepaths = [\n",
    "    '/workspaces/synthea_dw/data/fhir/AllergyIntolerance.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/CareTeam.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/Claim.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/Condition.ndjson'\n",
    "]\n",
    "concept = concept\n",
    "condition_occurrence_df = condition_occurrence(filepaths, concept)\n",
    "condition_occurrence_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_exposure_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>drug_concept_id</th>\n",
       "      <th>drug_exposure_start_date</th>\n",
       "      <th>drug_exposure_start_datetime</th>\n",
       "      <th>drug_exposure_end_date</th>\n",
       "      <th>drug_exposure_end_datetime</th>\n",
       "      <th>verbatim_end_date</th>\n",
       "      <th>drug_type_concept_id</th>\n",
       "      <th>stop_reason</th>\n",
       "      <th>refills</th>\n",
       "      <th>quantity</th>\n",
       "      <th>days_supply</th>\n",
       "      <th>sig</th>\n",
       "      <th>route_concept_id</th>\n",
       "      <th>lot_number</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>visit_detail_id</th>\n",
       "      <th>drug_source_value</th>\n",
       "      <th>drug_source_concept_id</th>\n",
       "      <th>route_source_value</th>\n",
       "      <th>dose_unit_source_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>adb6f4af-183a-823a-904b-f81d94a612ac</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>19041324</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>2018-01-21 12:15:03+00:00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>32817</td>\n",
       "      <td>stopped</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>d833f3f0-c08f-370e-b14a-1af90bc0adb3</td>\n",
       "      <td>6bfbdab2-d926-d13e-91e1-797ab9a396c0</td>\n",
       "      <td>None</td>\n",
       "      <td>209387</td>\n",
       "      <td>19041324</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>130573f9-556b-be34-cd81-da3996f35640</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>19080128</td>\n",
       "      <td>2017-07-23</td>\n",
       "      <td>2017-07-23 12:15:03+00:00</td>\n",
       "      <td>2017-07-23</td>\n",
       "      <td>2017-07-23 13:12:56+00:00</td>\n",
       "      <td>2017-07-23</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8a0add6a-00fa-b99f-ef92-531be4fe8f2a</td>\n",
       "      <td>None</td>\n",
       "      <td>314076</td>\n",
       "      <td>19080128</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>b70bf693-9244-d1cc-10a0-16ee972c6c44</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>19009384</td>\n",
       "      <td>2014-04-13</td>\n",
       "      <td>2014-04-13 12:15:03+00:00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>32817</td>\n",
       "      <td>stopped</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>d833f3f0-c08f-370e-b14a-1af90bc0adb3</td>\n",
       "      <td>76349a0d-58a7-b8b1-0294-825cac2452ed</td>\n",
       "      <td>None</td>\n",
       "      <td>106892</td>\n",
       "      <td>19009384</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>84023240-1548-2314-3b0f-ce8967be7fdb</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>19041324</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>2016-11-06 12:15:03+00:00</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>2016-11-06 12:57:35+00:00</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ae9d4e18-353f-8d6b-a917-765b73c63f88</td>\n",
       "      <td>None</td>\n",
       "      <td>209387</td>\n",
       "      <td>19041324</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>f71f3770-edab-8e00-f1ba-9116390a58e8</td>\n",
       "      <td>408a95f4-02aa-3003-2f09-0241ac3343fb</td>\n",
       "      <td>40166824</td>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>2023-04-05 08:52:48+00:00</td>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>2023-04-05 09:30:00+00:00</td>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>f5d43eb2-aefd-1a7c-1214-c9112cd19473</td>\n",
       "      <td>None</td>\n",
       "      <td>866412</td>\n",
       "      <td>40166824</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          drug_exposure_id                             person_id  drug_concept_id drug_exposure_start_date drug_exposure_start_datetime drug_exposure_end_date drug_exposure_end_datetime verbatim_end_date  drug_type_concept_id stop_reason refills quantity days_supply   sig route_concept_id lot_number                           provider_id                   visit_occurrence_id visit_detail_id drug_source_value  drug_source_concept_id route_source_value dose_unit_source_value\n",
       "1745  adb6f4af-183a-823a-904b-f81d94a612ac  7a7b7fba-a005-3736-91ef-218a0d2824c5         19041324               2018-01-21    2018-01-21 12:15:03+00:00                   <NA>                       <NA>              <NA>                 32817     stopped    <NA>     <NA>        <NA>  None             None       None  d833f3f0-c08f-370e-b14a-1af90bc0adb3  6bfbdab2-d926-d13e-91e1-797ab9a396c0            None            209387                19041324               None                   None\n",
       "634   130573f9-556b-be34-cd81-da3996f35640  7a7b7fba-a005-3736-91ef-218a0d2824c5         19080128               2017-07-23    2017-07-23 12:15:03+00:00             2017-07-23  2017-07-23 13:12:56+00:00        2017-07-23                 32817        None       0     None           1  None             None       None                                  None  8a0add6a-00fa-b99f-ef92-531be4fe8f2a            None            314076                19080128               None                   None\n",
       "1589  b70bf693-9244-d1cc-10a0-16ee972c6c44  7a7b7fba-a005-3736-91ef-218a0d2824c5         19009384               2014-04-13    2014-04-13 12:15:03+00:00                   <NA>                       <NA>              <NA>                 32817     stopped    <NA>     <NA>        <NA>  None             None       None  d833f3f0-c08f-370e-b14a-1af90bc0adb3  76349a0d-58a7-b8b1-0294-825cac2452ed            None            106892                19009384               None                   None\n",
       "609   84023240-1548-2314-3b0f-ce8967be7fdb  7a7b7fba-a005-3736-91ef-218a0d2824c5         19041324               2016-11-06    2016-11-06 12:15:03+00:00             2016-11-06  2016-11-06 12:57:35+00:00        2016-11-06                 32817        None       0     None           1  None             None       None                                  None  ae9d4e18-353f-8d6b-a917-765b73c63f88            None            209387                19041324               None                   None\n",
       "352   f71f3770-edab-8e00-f1ba-9116390a58e8  408a95f4-02aa-3003-2f09-0241ac3343fb         40166824               2023-04-05    2023-04-05 08:52:48+00:00             2023-04-05  2023-04-05 09:30:00+00:00        2023-04-05                 32817        None       0     None           1  None             None       None                                  None  f5d43eb2-aefd-1a7c-1214-c9112cd19473            None            866412                40166824               None                   None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drug_exposure(filepaths, concept, max_workers=10):\n",
    "    drug_exposures = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "        exposures = []\n",
    "\n",
    "        if resource_type == 'Claim' and any(coding['code'] == 'pharmacy' for coding in data['type']['coding']):\n",
    "            for item in data.get('item', []):\n",
    "                drug_exposure = {\n",
    "                    'drug_exposure_id': data['prescription']['reference'].split('/')[-1],\n",
    "                    'person_id': data['patient']['reference'].split('/')[-1],\n",
    "                    'drug_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[item['productOrService']['coding'][0]['code']], \n",
    "                        vocabulary_ids=['RxNorm'], \n",
    "                        domain_ids=['Drug'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S'\n",
    "                    ),\n",
    "                    'drug_exposure_start_date': datetime.strptime(data['billablePeriod']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                    'drug_exposure_start_datetime': datetime.fromisoformat(data['billablePeriod']['start']),\n",
    "                    'drug_exposure_end_date': datetime.strptime(data['billablePeriod']['end'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                    'drug_exposure_end_datetime': datetime.fromisoformat(data['billablePeriod']['end']),\n",
    "                    'verbatim_end_date': datetime.strptime(data['billablePeriod']['end'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                    'drug_type_concept_id': 32817,\n",
    "                    'stop_reason': None,\n",
    "                    'refills': 0,\n",
    "                    'quantity': None,\n",
    "                    'days_supply': ((datetime.strptime(data['billablePeriod']['start'].split('T')[0], '%Y-%m-%d').date()) - (datetime.strptime(data['billablePeriod']['start'].split('T')[0], '%Y-%m-%d').date())).days or 1,\n",
    "                    'sig': None,\n",
    "                    'route_concept_id': None,\n",
    "                    'lot_number': None,\n",
    "                    'provider_id': None,\n",
    "                    'visit_occurrence_id': item['encounter'][0]['reference'].split('/')[-1] if 'encounter' in item else None,\n",
    "                    'visit_detail_id': None,\n",
    "                    'drug_source_value': item['productOrService']['coding'][0]['code'],\n",
    "                    'drug_source_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[item['productOrService']['coding'][0]['code']], \n",
    "                        vocabulary_ids=['RxNorm'], \n",
    "                        domain_ids=['Drug']\n",
    "                    ),\n",
    "                    'route_source_value': None,\n",
    "                    'dose_unit_source_value': None\n",
    "                }\n",
    "                exposures.append(drug_exposure)\n",
    "\n",
    "        elif resource_type == 'Immunization':\n",
    "            person_id = data['patient']['reference'].split('/')[-1]\n",
    "            occurrence_date = datetime.strptime(data['occurrenceDateTime'].split('T')[0], '%Y-%m-%d').date()\n",
    "            occurrence_datetime = datetime.fromisoformat(data['occurrenceDateTime'])\n",
    "            visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "\n",
    "            for vaccineCode in data.get('vaccineCode', {}).get('coding', []):\n",
    "                drug_exposure = {\n",
    "                    'drug_exposure_id': data['id'],\n",
    "                    'person_id': person_id,\n",
    "                    'drug_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[vaccineCode['code']], \n",
    "                        vocabulary_ids=['CVX'], \n",
    "                        domain_ids=['Drug'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S'\n",
    "                    ),\n",
    "                    'drug_exposure_start_date': occurrence_date,\n",
    "                    'drug_exposure_start_datetime': occurrence_datetime,\n",
    "                    'drug_exposure_end_date': occurrence_date,\n",
    "                    'drug_exposure_end_datetime': occurrence_datetime,\n",
    "                    'verbatim_end_date': occurrence_date,\n",
    "                    'drug_type_concept_id': 32817,\n",
    "                    'stop_reason': 'completed' if data['status'] == 'completed' else None,\n",
    "                    'refills': 0,\n",
    "                    'quantity': 1,\n",
    "                    'days_supply': 1,\n",
    "                    'sig': None,\n",
    "                    'route_concept_id': None,\n",
    "                    'lot_number': None,\n",
    "                    'provider_id': None,\n",
    "                    'visit_occurrence_id': visit_occurrence_id,\n",
    "                    'visit_detail_id': None,\n",
    "                    'drug_source_value': vaccineCode['code'],\n",
    "                    'drug_source_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[vaccineCode['code']], \n",
    "                        vocabulary_ids=['CVX'], \n",
    "                        domain_ids=['Drug']\n",
    "                    ),\n",
    "                    'route_source_value': None,\n",
    "                    'dose_unit_source_value': None\n",
    "                }\n",
    "                exposures.append(drug_exposure)\n",
    "\n",
    "        elif resource_type == 'MedicationAdministration':\n",
    "            person_id = data['subject']['reference'].split('/')[-1]\n",
    "            visit_occurrence_id = data['context']['reference'].split('/')[-1] if 'context' in data else None\n",
    "            effective_date = datetime.strptime(data['effectiveDateTime'].split('T')[0], '%Y-%m-%d').date()\n",
    "\n",
    "            for coding in data['medicationCodeableConcept']['coding']:\n",
    "                drug_exposure = {\n",
    "                    'drug_exposure_id': data['id'],\n",
    "                    'person_id': person_id,\n",
    "                    'drug_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[coding['code']], \n",
    "                        vocabulary_ids=['RxNorm'], \n",
    "                        domain_ids=['Drug'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S'\n",
    "                    ),\n",
    "                    'drug_exposure_start_date': effective_date,\n",
    "                    'drug_exposure_start_datetime': datetime.fromisoformat(data['effectiveDateTime']),\n",
    "                    'drug_exposure_end_date': effective_date,\n",
    "                    'drug_exposure_end_datetime': datetime.fromisoformat(data['effectiveDateTime']),\n",
    "                    'verbatim_end_date': effective_date,\n",
    "                    'drug_type_concept_id': 32817,\n",
    "                    'stop_reason': 'completed' if data['status'] == 'completed' else None,\n",
    "                    'refills': 0,\n",
    "                    'quantity': 1,\n",
    "                    'days_supply': 1,\n",
    "                    'sig': None,\n",
    "                    'route_concept_id': None,\n",
    "                    'lot_number': None,\n",
    "                    'provider_id': None,\n",
    "                    'visit_occurrence_id': visit_occurrence_id,\n",
    "                    'visit_detail_id': None,\n",
    "                    'drug_source_value': coding['code'],\n",
    "                    'drug_source_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[coding['code']], \n",
    "                        vocabulary_ids=['RxNorm'], \n",
    "                        domain_ids=['Drug']\n",
    "                    ),\n",
    "                    'route_source_value': None,\n",
    "                    'dose_unit_source_value': None\n",
    "                }\n",
    "                exposures.append(drug_exposure)\n",
    "\n",
    "        elif resource_type == 'MedicationRequest':\n",
    "            if 'medicationCodeableConcept' in data and 'coding' in data['medicationCodeableConcept']:\n",
    "                person_id = data['subject']['reference'].split('/')[-1]\n",
    "                provider_id = data['requester']['reference'].split('/')[-1] if 'requester' in data else None\n",
    "                visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "                authored_date = datetime.strptime(data['authoredOn'].split('T')[0], '%Y-%m-%d').date()\n",
    "\n",
    "                for coding in data['medicationCodeableConcept']['coding']:\n",
    "                    drug_exposure = {\n",
    "                        'drug_exposure_id': data['id'],\n",
    "                        'person_id': person_id,\n",
    "                        'drug_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[coding['code']], \n",
    "                            vocabulary_ids=['RxNorm'], \n",
    "                            domain_ids=['Drug'], \n",
    "                            invalid_reason=False, \n",
    "                            standard_concept='S'\n",
    "                        ),\n",
    "                        'drug_exposure_start_date': authored_date,\n",
    "                        'drug_exposure_start_datetime': datetime.fromisoformat(data['authoredOn']),\n",
    "                        'drug_exposure_end_date': pd.NA,\n",
    "                        'drug_exposure_end_datetime': pd.NA,\n",
    "                        'verbatim_end_date': pd.NA,\n",
    "                        'drug_type_concept_id': 32817,\n",
    "                        'stop_reason': 'stopped' if data['status'] == 'stopped' else None,\n",
    "                        'refills': pd.NA,\n",
    "                        'quantity': pd.NA,\n",
    "                        'days_supply': pd.NA,\n",
    "                        'sig': None,\n",
    "                        'route_concept_id': None,\n",
    "                        'lot_number': None,\n",
    "                        'provider_id': provider_id,\n",
    "                        'visit_occurrence_id': visit_occurrence_id,\n",
    "                        'visit_detail_id': None,\n",
    "                        'drug_source_value': coding['code'],\n",
    "                        'drug_source_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[coding['code']], \n",
    "                            vocabulary_ids=['RxNorm'], \n",
    "                            domain_ids=['Drug']\n",
    "                        ),\n",
    "                        'route_source_value': None,\n",
    "                        'dose_unit_source_value': None\n",
    "                    }\n",
    "                    exposures.append(drug_exposure)\n",
    "\n",
    "        return exposures\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "            for future in as_completed(future_to_line):\n",
    "                drug_exposures.extend(future.result())\n",
    "\n",
    "    drug_exposure = pd.DataFrame(drug_exposures).drop_duplicates()\n",
    "    drug_exposure = drug_exposure[drug_exposure['drug_source_concept_id'] != 0]\n",
    "\n",
    "    return drug_exposure\n",
    "\n",
    "filepaths = [\n",
    "    '/workspaces/synthea_dw/data/fhir/Claim.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/Immunization.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/MedicationAdministration.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/MedicationRequest.ndjson'\n",
    "]\n",
    "concept = concept\n",
    "drug_exposure_df = drug_exposure(filepaths, concept)\n",
    "drug_exposure_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>procedure_occurrence_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>procedure_concept_id</th>\n",
       "      <th>procedure_date</th>\n",
       "      <th>procedure_datetime</th>\n",
       "      <th>procedure_end_date</th>\n",
       "      <th>procedure_end_datetime</th>\n",
       "      <th>procedure_type_concept_id</th>\n",
       "      <th>modifier_concept_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>visit_detail_id</th>\n",
       "      <th>procedure_source_value</th>\n",
       "      <th>procedure_source_concept_id</th>\n",
       "      <th>modifier_source_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>0b2170d1-d7ed-2261-590f-2c8debb3a2dc</td>\n",
       "      <td>408a95f4-02aa-3003-2f09-0241ac3343fb</td>\n",
       "      <td>762506</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2020-03-18 10:43:14+00:00</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>2020-03-18 10:53:55+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2591259b-95e9-e6cf-bb45-82b3676f9fc2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>428211000124100</td>\n",
       "      <td>762506</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>4d4d6eab-5afc-4fc4-568f-0cfc125a415d</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>4146536</td>\n",
       "      <td>2022-06-25</td>\n",
       "      <td>2022-06-25 18:11:03+00:00</td>\n",
       "      <td>2022-06-25</td>\n",
       "      <td>2022-06-25 21:52:03+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>790fa7c6-516e-0e70-c8c1-371556580834</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>265764009</td>\n",
       "      <td>4146536</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>6b19781f-5af2-0c06-e6e4-e3b73c9031b7</td>\n",
       "      <td>7a82833f-fae1-d69a-2cbf-69279dac746f</td>\n",
       "      <td>762506</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021-01-02 03:17:25+00:00</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021-01-02 03:27:58+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>805c3232-6446-6b62-9cfb-48d6bf7133dd</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>428211000124100</td>\n",
       "      <td>762506</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>efaa3271-f64e-9e27-3c29-026acddd00bf</td>\n",
       "      <td>7a7b7fba-a005-3736-91ef-218a0d2824c5</td>\n",
       "      <td>46272459</td>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>2015-11-15 12:15:03+00:00</td>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>2015-11-15 13:02:45+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>9081c31a-1aab-35ab-f477-9e4793c9c9af</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>710824005</td>\n",
       "      <td>46272459</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>f7dd8cae-da6d-d9c0-3ceb-0ed8cbd097c3</td>\n",
       "      <td>4390395b-5a78-2005-80b7-5ebd62b595c9</td>\n",
       "      <td>46272459</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2020-12-30 07:11:38+00:00</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2020-12-30 07:57:31+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>f89dde2a-4483-92ae-b94e-d6d14b6a4454</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>710824005</td>\n",
       "      <td>46272459</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   procedure_occurrence_id                             person_id  procedure_concept_id procedure_date        procedure_datetime procedure_end_date    procedure_end_datetime  procedure_type_concept_id modifier_concept_id  quantity provider_id                   visit_occurrence_id visit_detail_id procedure_source_value  procedure_source_concept_id modifier_source_value\n",
       "946   0b2170d1-d7ed-2261-590f-2c8debb3a2dc  408a95f4-02aa-3003-2f09-0241ac3343fb                762506     2020-03-18 2020-03-18 10:43:14+00:00         2020-03-18 2020-03-18 10:53:55+00:00                      32817                   0         1        <NA>  2591259b-95e9-e6cf-bb45-82b3676f9fc2            <NA>        428211000124100                       762506                  None\n",
       "2117  4d4d6eab-5afc-4fc4-568f-0cfc125a415d  7a7b7fba-a005-3736-91ef-218a0d2824c5               4146536     2022-06-25 2022-06-25 18:11:03+00:00         2022-06-25 2022-06-25 21:52:03+00:00                      32817                   0         1        <NA>  790fa7c6-516e-0e70-c8c1-371556580834            <NA>              265764009                      4146536                  None\n",
       "1024  6b19781f-5af2-0c06-e6e4-e3b73c9031b7  7a82833f-fae1-d69a-2cbf-69279dac746f                762506     2021-01-02 2021-01-02 03:17:25+00:00         2021-01-02 2021-01-02 03:27:58+00:00                      32817                   0         1        <NA>  805c3232-6446-6b62-9cfb-48d6bf7133dd            <NA>        428211000124100                       762506                  None\n",
       "1313  efaa3271-f64e-9e27-3c29-026acddd00bf  7a7b7fba-a005-3736-91ef-218a0d2824c5              46272459     2015-11-15 2015-11-15 12:15:03+00:00         2015-11-15 2015-11-15 13:02:45+00:00                      32817                   0         1        <NA>  9081c31a-1aab-35ab-f477-9e4793c9c9af            <NA>              710824005                     46272459                  None\n",
       "451   f7dd8cae-da6d-d9c0-3ceb-0ed8cbd097c3  4390395b-5a78-2005-80b7-5ebd62b595c9              46272459     2020-12-30 2020-12-30 07:11:38+00:00         2020-12-30 2020-12-30 07:57:31+00:00                      32817                   0         1        <NA>  f89dde2a-4483-92ae-b94e-d6d14b6a4454            <NA>              710824005                     46272459                  None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def procedure_occurrence(filepaths, concept, max_workers=10):\n",
    "    procedure_occurrences = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "        procedures = []\n",
    "\n",
    "        if resource_type == 'CarePlan':\n",
    "            for category in data.get('category', []):\n",
    "                for coding in category.get('coding', []):\n",
    "                    if 'display' in coding:\n",
    "                        procedure = {\n",
    "                            'procedure_occurrence_id': data['id'],\n",
    "                            'person_id': data['subject']['reference'].split('/')[-1],\n",
    "                            'procedure_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Procedure'], \n",
    "                                invalid_reason=False, \n",
    "                                standard_concept='S', \n",
    "                                concept_class_ids=['Procedure']\n",
    "                            ),\n",
    "                            'procedure_date': datetime.strptime(data['period']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                            'procedure_datetime': datetime.fromisoformat(data['period']['start']),\n",
    "                            'procedure_end_date': None,\n",
    "                            'procedure_end_datetime': None,\n",
    "                            'procedure_type_concept_id': 32817,\n",
    "                            'modifier_concept_id': pd.NA,\n",
    "                            'quantity': 1,\n",
    "                            'provider_id': pd.NA,\n",
    "                            'visit_occurrence_id': data['encounter']['reference'].split('/')[-1],\n",
    "                            'visit_detail_id': pd.NA,\n",
    "                            'procedure_source_value': coding['code'],\n",
    "                            'procedure_source_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Procedure'], \n",
    "                                concept_class_ids=['Procedure']\n",
    "                            ),\n",
    "                            'modifier_source_value': None\n",
    "                        }\n",
    "                        procedures.append(procedure)\n",
    "\n",
    "        elif resource_type == 'ImagingStudy':\n",
    "            person_id = data['subject']['reference'].split('/')[-1]\n",
    "            procedure_date = datetime.strptime(data['started'].split('T')[0], '%Y-%m-%d').date()\n",
    "            procedure_datetime = datetime.fromisoformat(data['started'])\n",
    "            visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "            numberOfInstances = data['numberOfInstances'] if 'numberOfInstances' in data else None\n",
    "\n",
    "            for procedureCode in data.get('procedureCode', []):\n",
    "                for coding in procedureCode.get('coding', []):\n",
    "                    modifier_code = data['series'][0]['bodySite']['code'] if 'series' in data and 'bodySite' in data['series'][0] else None\n",
    "\n",
    "                    procedure_occurrence = {\n",
    "                        'procedure_occurrence_id': data['id'],\n",
    "                        'person_id': person_id,\n",
    "                        'procedure_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[coding['code']], \n",
    "                            vocabulary_ids=['SNOMED'], \n",
    "                            domain_ids=['Procedure'], \n",
    "                            invalid_reason=False, \n",
    "                            standard_concept='S'\n",
    "                        ),\n",
    "                        'procedure_date': procedure_date,\n",
    "                        'procedure_datetime': procedure_datetime,\n",
    "                        'procedure_end_date': None,\n",
    "                        'procedure_end_datetime': None,\n",
    "                        'procedure_type_concept_id': 32817,\n",
    "                        'modifier_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[modifier_code], \n",
    "                            vocabulary_ids=['SNOMED'], \n",
    "                            domain_ids=['Spec Anatomic Site'], \n",
    "                            invalid_reason=False, \n",
    "                            standard_concept='S'\n",
    "                        ),\n",
    "                        'quantity': numberOfInstances,\n",
    "                        'provider_id': pd.NA,\n",
    "                        'visit_occurrence_id': visit_occurrence_id,\n",
    "                        'visit_detail_id': pd.NA,\n",
    "                        'procedure_source_value': coding['display'] if 'display' in coding else None,\n",
    "                        'procedure_source_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[coding['code']], \n",
    "                            vocabulary_ids=['SNOMED'], \n",
    "                            domain_ids=['Procedure'], \n",
    "                            invalid_reason=False, \n",
    "                            standard_concept='S'\n",
    "                        ),\n",
    "                        'modifier_source_value': modifier_code\n",
    "                    }\n",
    "                    procedures.append(procedure_occurrence)\n",
    "\n",
    "        elif resource_type == 'Procedure':\n",
    "            person_id = data['subject']['reference'].split('/')[-1]\n",
    "            procedure_code = data['code']['coding'][0]['code']\n",
    "            procedure_date = datetime.strptime(data['performedPeriod']['start'].split('T')[0], '%Y-%m-%d').date()\n",
    "            procedure_datetime = datetime.fromisoformat(data['performedPeriod']['start'])\n",
    "            procedure_end_date = datetime.strptime(data['performedPeriod']['end'].split('T')[0], '%Y-%m-%d').date() if 'end' in data['performedPeriod'] else None\n",
    "            procedure_end_datetime = datetime.fromisoformat(data['performedPeriod']['end']) if 'end' in data['performedPeriod'] else None\n",
    "            visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "\n",
    "            procedure_occurrence = {\n",
    "                'procedure_occurrence_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'procedure_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Procedure'], \n",
    "                    invalid_reason=False, \n",
    "                    standard_concept='S'\n",
    "                ),\n",
    "                'procedure_date': procedure_date,\n",
    "                'procedure_datetime': procedure_datetime,\n",
    "                'procedure_end_date': procedure_end_date,\n",
    "                'procedure_end_datetime': procedure_end_datetime,\n",
    "                'procedure_type_concept_id': 32817,\n",
    "                'modifier_concept_id': 0,\n",
    "                'quantity': 1,\n",
    "                'provider_id': pd.NA,\n",
    "                'visit_occurrence_id': visit_occurrence_id,\n",
    "                'visit_detail_id': pd.NA,\n",
    "                'procedure_source_value': procedure_code,\n",
    "                'procedure_source_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Procedure']\n",
    "                ),\n",
    "                'modifier_source_value': None\n",
    "            }\n",
    "\n",
    "            procedures.append(procedure_occurrence)\n",
    "\n",
    "        return procedures\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                procedure_occurrences.extend(future.result())\n",
    "\n",
    "    procedure_occurrence = pd.DataFrame(procedure_occurrences).drop_duplicates()\n",
    "    procedure_occurrence = procedure_occurrence[procedure_occurrence['procedure_source_concept_id'] != 0]\n",
    "\n",
    "    return procedure_occurrence\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/CarePlan.ndjson', '/workspaces/synthea_dw/data/fhir/ImagingStudy.ndjson', '/workspaces/synthea_dw/data/fhir/Procedure.ndjson']\n",
    "concept = concept\n",
    "procedure_occurrence_df = procedure_occurrence(filepaths, concept)\n",
    "procedure_occurrence_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_exposure_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>device_concept_id</th>\n",
       "      <th>device_exposure_start_date</th>\n",
       "      <th>device_exposure_start_datetime</th>\n",
       "      <th>device_exposure_end_date</th>\n",
       "      <th>device_exposure_end_datetime</th>\n",
       "      <th>device_type_concept_id</th>\n",
       "      <th>unique_device_id</th>\n",
       "      <th>production_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>provider_id</th>\n",
       "      <th>visit_occurrence_id</th>\n",
       "      <th>visit_detail_id</th>\n",
       "      <th>device_source_value</th>\n",
       "      <th>device_source_concept_id</th>\n",
       "      <th>unit_concept_id</th>\n",
       "      <th>unit_source_value</th>\n",
       "      <th>unit_source_concept_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>c12aab6d-fb7b-673e-834b-73ca80e15f29</td>\n",
       "      <td>4390395b-5a78-2005-80b7-5ebd62b595c9</td>\n",
       "      <td>605721</td>\n",
       "      <td>2014-11-26</td>\n",
       "      <td>2014-11-26 07:11:38+00:00</td>\n",
       "      <td>2014-11-26</td>\n",
       "      <td>2014-11-26 07:11:38+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1137596000</td>\n",
       "      <td>605721</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>4b51e00e-6308-6f4f-0bc4-cb211c11fb92</td>\n",
       "      <td>c86bea4c-5647-c8c2-35c5-cb08246ded70</td>\n",
       "      <td>45758780</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2021-08-27 16:03:44+00:00</td>\n",
       "      <td>2021-08-27</td>\n",
       "      <td>2021-08-27 16:03:44+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>463659001</td>\n",
       "      <td>45758780</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6969115a-d68f-ee3c-7d8a-61169637449b</td>\n",
       "      <td>c86bea4c-5647-c8c2-35c5-cb08246ded70</td>\n",
       "      <td>4222987</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>2011-07-01 16:03:44+00:00</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>2011-07-01 16:03:44+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>337388004</td>\n",
       "      <td>4222987</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5f44c6e2-c228-1fbc-dd96-36a391349608</td>\n",
       "      <td>32ee64c2-1585-d7ad-c53f-9ad739c676cf</td>\n",
       "      <td>4222987</td>\n",
       "      <td>2011-11-27</td>\n",
       "      <td>2011-11-27 12:15:03+00:00</td>\n",
       "      <td>2011-11-27</td>\n",
       "      <td>2011-11-27 12:15:03+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>337388004</td>\n",
       "      <td>4222987</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>829b1d33-4e46-1e0c-c083-44ecab3eae04</td>\n",
       "      <td>c86bea4c-5647-c8c2-35c5-cb08246ded70</td>\n",
       "      <td>45758780</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>2020-06-19 16:03:44+00:00</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>2020-06-19 16:03:44+00:00</td>\n",
       "      <td>32817</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>463659001</td>\n",
       "      <td>45758780</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       device_exposure_id                             person_id  device_concept_id device_exposure_start_date device_exposure_start_datetime device_exposure_end_date device_exposure_end_datetime  device_type_concept_id unique_device_id production_id  quantity provider_id visit_occurrence_id visit_detail_id device_source_value  device_source_concept_id unit_concept_id unit_source_value unit_source_concept_id\n",
       "84   c12aab6d-fb7b-673e-834b-73ca80e15f29  4390395b-5a78-2005-80b7-5ebd62b595c9             605721                 2014-11-26      2014-11-26 07:11:38+00:00               2014-11-26    2014-11-26 07:11:38+00:00                   32817             None          None       100        <NA>                <NA>            <NA>          1137596000                    605721            <NA>              None                   <NA>\n",
       "165  4b51e00e-6308-6f4f-0bc4-cb211c11fb92  c86bea4c-5647-c8c2-35c5-cb08246ded70           45758780                 2021-08-27      2021-08-27 16:03:44+00:00               2021-08-27    2021-08-27 16:03:44+00:00                   32817             None          None         1        <NA>                <NA>            <NA>           463659001                  45758780            <NA>              None                   <NA>\n",
       "65   6969115a-d68f-ee3c-7d8a-61169637449b  c86bea4c-5647-c8c2-35c5-cb08246ded70            4222987                 2011-07-01      2011-07-01 16:03:44+00:00               2011-07-01    2011-07-01 16:03:44+00:00                   32817             None          None        50        <NA>                <NA>            <NA>           337388004                   4222987            <NA>              None                   <NA>\n",
       "95   5f44c6e2-c228-1fbc-dd96-36a391349608  32ee64c2-1585-d7ad-c53f-9ad739c676cf            4222987                 2011-11-27      2011-11-27 12:15:03+00:00               2011-11-27    2011-11-27 12:15:03+00:00                   32817             None          None        50        <NA>                <NA>            <NA>           337388004                   4222987            <NA>              None                   <NA>\n",
       "149  829b1d33-4e46-1e0c-c083-44ecab3eae04  c86bea4c-5647-c8c2-35c5-cb08246ded70           45758780                 2020-06-19      2020-06-19 16:03:44+00:00               2020-06-19    2020-06-19 16:03:44+00:00                   32817             None          None         1        <NA>                <NA>            <NA>           463659001                  45758780            <NA>              None                   <NA>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def device_exposure(filepaths, concept, max_workers=10):\n",
    "    device_exposures = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "        exposures = []\n",
    "\n",
    "        if resource_type == 'Device':\n",
    "            person_id = data['patient']['reference'].split('/')[-1]\n",
    "            device_code = data['type']['coding'][0]['code']\n",
    "            exposure = {\n",
    "                'device_exposure_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'device_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[device_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Device'], \n",
    "                    invalid_reason=False, \n",
    "                    standard_concept='S'\n",
    "                ),\n",
    "                'device_exposure_start_date': datetime.strptime(data['manufactureDate'].split('T')[0], '%Y-%m-%d').date() if 'manufactureDate' in data else None,\n",
    "                'device_exposure_start_datetime': datetime.fromisoformat(data['manufactureDate']) if 'manufactureDate' in data else None,\n",
    "                'device_exposure_end_date': None,\n",
    "                'device_exposure_end_datetime': None,\n",
    "                'device_type_concept_id': 32817,\n",
    "                'unique_device_id': data.get('distinctIdentifier', None),\n",
    "                'production_id': data['udiCarrier'][0]['carrierHRF'] if 'udiCarrier' in data else None,\n",
    "                'quantity': 1,\n",
    "                'provider_id': pd.NA,\n",
    "                'visit_occurrence_id': pd.NA,\n",
    "                'visit_detail_id': pd.NA,\n",
    "                'device_source_value': device_code,\n",
    "                'device_source_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[device_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Device']\n",
    "                ),\n",
    "                'unit_concept_id': pd.NA,\n",
    "                'unit_source_value': None,\n",
    "                'unit_source_concept_id': pd.NA\n",
    "            }\n",
    "            exposures.append(exposure)\n",
    "\n",
    "        elif resource_type == 'SupplyDelivery':\n",
    "            person_id = data['patient']['reference'].split('/')[-1]\n",
    "            device_code = data['suppliedItem']['itemCodeableConcept']['coding'][0]['code']\n",
    "            quantity = data['suppliedItem']['quantity']['value'] if 'quantity' in data['suppliedItem'] else None\n",
    "            occurrence_date = datetime.strptime(data['occurrenceDateTime'].split('T')[0], '%Y-%m-%d').date() if 'occurrenceDateTime' in data else None\n",
    "            occurrence_datetime = datetime.fromisoformat(data['occurrenceDateTime']) if 'occurrenceDateTime' in data else None\n",
    "\n",
    "            exposure = {\n",
    "                'device_exposure_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'device_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[device_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Device'], \n",
    "                    invalid_reason=False, \n",
    "                    standard_concept='S'\n",
    "                ),\n",
    "                'device_exposure_start_date': occurrence_date,\n",
    "                'device_exposure_start_datetime': occurrence_datetime,\n",
    "                'device_exposure_end_date': occurrence_date,\n",
    "                'device_exposure_end_datetime': occurrence_datetime,\n",
    "                'device_type_concept_id': 32817,\n",
    "                'unique_device_id': None,\n",
    "                'production_id': None,\n",
    "                'quantity': quantity,\n",
    "                'provider_id': pd.NA,\n",
    "                'visit_occurrence_id': pd.NA,\n",
    "                'visit_detail_id': pd.NA,\n",
    "                'device_source_value': device_code,\n",
    "                'device_source_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[device_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Device']\n",
    "                ),\n",
    "                'unit_concept_id': pd.NA,\n",
    "                'unit_source_value': None,\n",
    "                'unit_source_concept_id': pd.NA\n",
    "            }\n",
    "            exposures.append(exposure)\n",
    "\n",
    "        return exposures\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                device_exposures.extend(future.result())\n",
    "\n",
    "    device_exposure = pd.DataFrame(device_exposures).drop_duplicates()\n",
    "    device_exposure = device_exposure[device_exposure['device_source_concept_id'] != 0]\n",
    "\n",
    "    return device_exposure\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Device.ndjson', '/workspaces/synthea_dw/data/fhir/SupplyDelivery.ndjson']\n",
    "device_exposure_df = device_exposure(filepaths, concept)\n",
    "device_exposure_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement(filepaths, concept, max_workers=10):\n",
    "    measurement_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "        measurements = []\n",
    "\n",
    "        person_id = data['subject']['reference'].split('/')[-1]\n",
    "        visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "\n",
    "        if resource_type == 'Observation':\n",
    "            measurement_date = datetime.strptime(data['effectiveDateTime'].split('T')[0], '%Y-%m-%d').date() if 'effectiveDateTime' in data else None\n",
    "            measurement_datetime = datetime.fromisoformat(data['effectiveDateTime']) if 'effectiveDateTime' in data else None\n",
    "            measurement_time = data['effectiveDateTime'].split('T')[1] if 'effectiveDateTime' in data else None\n",
    "            components = data.get('component', [{'code': data['code'], 'valueQuantity': data.get('valueQuantity')}])\n",
    "\n",
    "            for comp in components:\n",
    "                code = comp['code']['coding'][0]['code']\n",
    "                valueQuantity = comp.get('valueQuantity', None)\n",
    "                value_as_number = float(valueQuantity['value']) if valueQuantity and 'value' in valueQuantity else pd.NA\n",
    "\n",
    "                measurement = {\n",
    "                    'measurement_id': data['id'],\n",
    "                    'person_id': person_id,\n",
    "                    'measurement_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[code], \n",
    "                        vocabulary_ids=['LOINC'], \n",
    "                        domain_ids=['Measurement'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S'\n",
    "                    ),\n",
    "                    'measurement_date': measurement_date,\n",
    "                    'measurement_datetime': measurement_datetime,\n",
    "                    'measurement_time': measurement_time,\n",
    "                    'measurement_type_concept_id': 32817,\n",
    "                    'operator_concept_id': 4172703,\n",
    "                    'value_as_number': value_as_number,\n",
    "                    'value_as_concept_id': pd.NA,\n",
    "                    'unit_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[valueQuantity['code']] if valueQuantity and 'code' in valueQuantity else None, \n",
    "                        vocabulary_ids=['UCUM'], domain_ids=['Unit'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S'\n",
    "                    ),\n",
    "                    'range_low': pd.NA,\n",
    "                    'range_high': pd.NA,\n",
    "                    'provider_id': pd.NA,\n",
    "                    'visit_occurrence_id': visit_occurrence_id,\n",
    "                    'visit_detail_id': pd.NA,\n",
    "                    'measurement_source_value': code,\n",
    "                    'measurement_source_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[code], \n",
    "                        vocabulary_ids=['LOINC'], \n",
    "                        domain_ids=['Measurement']\n",
    "                    ),\n",
    "                    'unit_source_value': valueQuantity['code'] if valueQuantity and 'code' in valueQuantity else None,\n",
    "                    'unit_source_concept_id': pd.NA,\n",
    "                    'value_source_value': valueQuantity['value'] if valueQuantity and 'value' in valueQuantity else None,\n",
    "                    'measurement_event_id': pd.NA,\n",
    "                    'meas_event_field_concept_id': pd.NA\n",
    "                }\n",
    "                measurements.append(measurement)\n",
    "\n",
    "        elif resource_type == 'Procedure':\n",
    "            procedure_code = data['code']['coding'][0]['code']\n",
    "            measurement_date = datetime.strptime(data['performedPeriod']['start'].split('T')[0], '%Y-%m-%d').date() if 'performedPeriod' in data and 'start' in data['performedPeriod'] else None\n",
    "            measurement_datetime = datetime.fromisoformat(data['performedPeriod']['start']) if 'performedPeriod' in data and 'start' in data['performedPeriod'] else None\n",
    "\n",
    "            measurement = {\n",
    "                'measurement_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'measurement_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Measurement'], \n",
    "                    invalid_reason=False, \n",
    "                    standard_concept='S'\n",
    "                ),\n",
    "                'measurement_date': measurement_date,\n",
    "                'measurement_datetime': measurement_datetime,\n",
    "                'measurement_time': None,\n",
    "                'measurement_type_concept_id': 32817,\n",
    "                'operator_concept_id': 4172703,\n",
    "                'value_as_number': pd.NA,\n",
    "                'value_as_concept_id': 0,\n",
    "                'unit_concept_id': 0,\n",
    "                'range_low': pd.NA,\n",
    "                'range_high': pd.NA,\n",
    "                'provider_id': pd.NA,\n",
    "                'visit_occurrence_id': visit_occurrence_id,\n",
    "                'visit_detail_id': pd.NA,\n",
    "                'measurement_source_value': procedure_code,\n",
    "                'measurement_source_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Measurement']\n",
    "                ),\n",
    "                'unit_source_value': None,\n",
    "                'unit_source_concept_id': 0,\n",
    "                'value_source_value': None,\n",
    "                'measurement_event_id': pd.NA,\n",
    "                'meas_event_field_concept_id': pd.NA\n",
    "            }\n",
    "            measurements.append(measurement)\n",
    "\n",
    "        return measurements\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                measurement_rows.extend(future.result())\n",
    "\n",
    "    measurement = pd.DataFrame(measurement_rows).drop_duplicates()\n",
    "    measurement = measurement[measurement['measurement_source_concept_id'] != 0]\n",
    "\n",
    "    return measurement\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Observation.ndjson', '/workspaces/synthea_dw/data/fhir/Procedure.ndjson']\n",
    "measurement_df = measurement(filepaths, concept)\n",
    "measurement_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation(filepaths, concept, max_workers=10):\n",
    "    observation_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "        observations = []\n",
    "\n",
    "        person_id = data['subject']['reference'].split('/')[-1]\n",
    "        visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "\n",
    "        if resource_type == 'AllergyIntolerance' and data['code']['coding'][0]['code'] != '419199007':\n",
    "            for reaction in data.get('reaction', []):\n",
    "                observation = {\n",
    "                    'observation_id': data['id'],\n",
    "                    'person_id': data['patient']['reference'].split('/')[-1],\n",
    "                    'observation_concept_id': 4169307,\n",
    "                    'observation_date': datetime.strptime(data['recordedDate'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                    'observation_datetime': datetime.fromisoformat(data['recordedDate']),\n",
    "                    'observation_type_concept_id': 32817,\n",
    "                    'value_as_number': None,\n",
    "                    'value_as_string': None,\n",
    "                    'value_as_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[data['code']['coding'][0]['code']], \n",
    "                        vocabulary_ids=['SNOMED'], \n",
    "                        domain_ids=['Observation'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S', \n",
    "                        concept_class_ids=['Substance']\n",
    "                    ),\n",
    "                    'qualifier_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_names=[data['criticality'].capitalize()], \n",
    "                        vocabulary_ids=['SNOMED'], \n",
    "                        domain_ids=['Meas Value'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S',\n",
    "                        concept_class_ids=['Qualifier Value']\n",
    "                    ),\n",
    "                    'unit_concept_id': pd.NA,\n",
    "                    'provider_id': pd.NA,\n",
    "                    'visit_occurrence_id': None,\n",
    "                    'visit_detail_id': None,\n",
    "                    'observation_source_value': None,\n",
    "                    'observation_source_concept_id': 4169307,\n",
    "                    'unit_source_value': None,\n",
    "                    'qualifier_source_value': data['criticality'],\n",
    "                    'value_source_value': data['code']['coding'][0]['code'],\n",
    "                    'observation_event_id': None,\n",
    "                    'obs_event_field_concept_id': None\n",
    "                }\n",
    "                observations.append(observation)\n",
    "\n",
    "        elif resource_type == 'CarePlan':\n",
    "            for category in data.get('category', []):\n",
    "                for coding in category.get('coding', []):\n",
    "                    if 'display' in coding:\n",
    "                        observation = {\n",
    "                            'observation_id': data['id'],\n",
    "                            'person_id': data['subject']['reference'].split('/')[-1],\n",
    "                            'observation_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Observation'], \n",
    "                                invalid_reason=False, \n",
    "                                standard_concept='S'\n",
    "                            ),\n",
    "                            'observation_date': datetime.strptime(data['period']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                            'observation_datetime': datetime.fromisoformat(data['period']['start']),\n",
    "                            'observation_type_concept_id': 32817,\n",
    "                            'value_as_number': None,\n",
    "                            'value_as_string': None,\n",
    "                            'value_as_concept_id': pd.NA,\n",
    "                            'qualifier_concept_id': pd.NA,\n",
    "                            'unit_concept_id': pd.NA,\n",
    "                            'provider_id': pd.NA,\n",
    "                            'visit_occurrence_id': data['encounter']['reference'].split('/')[-1],\n",
    "                            'visit_detail_id': pd.NA,\n",
    "                            'observation_source_value': coding['code'],\n",
    "                            'observation_source_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Observation']\n",
    "                            ),\n",
    "                            'qualifier_source_value': None,\n",
    "                            'value_source_value': None,\n",
    "                            'observation_event_id': data['id'],\n",
    "                            'obs_event_field_concept_id': None  \n",
    "                        }\n",
    "                        observations.append(observation)\n",
    "\n",
    "        elif resource_type == 'Claim' and any(coding['code'] in ['professional', 'institutional'] for coding in data['type']['coding']):\n",
    "            person_id = data['patient']['reference'].split('/')[-1]\n",
    "\n",
    "            for item in data.get('item', []):\n",
    "                if 'productOrService' in item and 'coding' in item['productOrService']:\n",
    "                    for coding in item['productOrService']['coding']:\n",
    "                        observation = {\n",
    "                            'observation_id': data['id'],\n",
    "                            'person_id': person_id,\n",
    "                            'observation_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Observation'], \n",
    "                                invalid_reason=False, \n",
    "                                standard_concept='S'\n",
    "                            ),\n",
    "                            'observation_date': datetime.strptime(data['created'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                            'observation_datetime': datetime.fromisoformat(data['created']),\n",
    "                            'observation_type_concept_id': 32817,\n",
    "                            'value_as_number': pd.NA,\n",
    "                            'value_as_string': None,\n",
    "                            'value_as_concept_id': pd.NA,\n",
    "                            'qualifier_concept_id': pd.NA,\n",
    "                            'unit_concept_id': None,\n",
    "                            'provider_id': pd.NA,\n",
    "                            'visit_occurrence_id': item['encounter'][0]['reference'].split('/')[-1] if 'encounter' in item else None,\n",
    "                            'visit_detail_id': pd.NA,\n",
    "                            'observation_source_value': coding['code'],\n",
    "                            'observation_source_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Observation']\n",
    "                            ),\n",
    "                            'unit_source_value': None,\n",
    "                            'qualifier_source_value': None,\n",
    "                            'value_source_value': None,\n",
    "                            'observation_event_id': data['id'],\n",
    "                            'obs_event_field_concept_id': None\n",
    "                        }\n",
    "                        observations.append(observation)\n",
    "\n",
    "        elif resource_type == 'Observation':\n",
    "            person_id = data['subject']['reference'].split('/')[-1]\n",
    "            observation_date = datetime.strptime(data['effectiveDateTime'].split('T')[0], '%Y-%m-%d').date() if 'effectiveDateTime' in data else None\n",
    "            observation_datetime = datetime.fromisoformat(data['effectiveDateTime']) if 'effectiveDateTime' in data else None\n",
    "            visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "\n",
    "            if 'component' in data:\n",
    "                for comp in data['component']:\n",
    "                    code = comp['code']['coding'][0]['code']\n",
    "                    valueQuantity = comp.get('valueQuantity', None)\n",
    "                    valueCodeableConcept = comp.get('valueCodeableConcept', None)\n",
    "\n",
    "                    value_as_number = float(valueQuantity['value']) if valueQuantity and 'value' in valueQuantity else pd.NA\n",
    "                    value_as_concept_id = find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[valueCodeableConcept['coding'][0]['code']], \n",
    "                        vocabulary_ids=['LOINC'], \n",
    "                        domain_ids=['Meas Value']\n",
    "                    ) if valueCodeableConcept else None\n",
    "\n",
    "                    observation = {\n",
    "                        'observation_id': data['id'],\n",
    "                        'person_id': person_id,\n",
    "                        'observation_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[code], \n",
    "                            vocabulary_ids=['LOINC'], \n",
    "                            domain_ids=['Observation'], \n",
    "                            invalid_reason=False, \n",
    "                            standard_concept='S'\n",
    "                        ),\n",
    "                        'observation_date': observation_date,\n",
    "                        'observation_datetime': observation_datetime,\n",
    "                        'observation_type_concept_id': 32817,\n",
    "                        'value_as_number': value_as_number,\n",
    "                        'value_as_concept_id': value_as_concept_id,\n",
    "                        'unit_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[valueQuantity['code']] if valueQuantity and 'code' in valueQuantity else None, \n",
    "                            vocabulary_ids=['UCUM'], \n",
    "                            domain_ids=['Unit'], \n",
    "                            invalid_reason=False, \n",
    "                            standard_concept='S'\n",
    "                        ) if valueQuantity and 'code' in valueQuantity else pd.NA,\n",
    "                        'provider_id': pd.NA,\n",
    "                        'visit_occurrence_id': visit_occurrence_id,\n",
    "                        'visit_detail_id': pd.NA,\n",
    "                        'observation_source_value': code,\n",
    "                        'observation_source_concept_id': find_concept_id(\n",
    "                            concept, \n",
    "                            concept_codes=[code], \n",
    "                            vocabulary_ids=['LOINC'], \n",
    "                            domain_ids=['Observation']\n",
    "                        ),\n",
    "                        'unit_source_value': valueQuantity['code'] if valueQuantity and 'code' in valueQuantity else None,\n",
    "                        'qualifier_source_value': None,\n",
    "                        'value_source_value': valueQuantity['value'] if valueQuantity and 'value' in valueQuantity else None,\n",
    "                        'observation_event_id': data['id'],\n",
    "                        'obs_event_field_concept_id': pd.NA\n",
    "                    }\n",
    "                    observations.append(observation)\n",
    "            \n",
    "            else:\n",
    "                code = data['code']['coding'][0]['code']\n",
    "                valueQuantity = data.get('valueQuantity', None)\n",
    "                valueCodeableConcept = data.get('valueCodeableConcept', None)\n",
    "\n",
    "                value_as_number = float(valueQuantity['value']) if valueQuantity and 'value' in valueQuantity else pd.NA\n",
    "                value_as_concept_id = find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[valueCodeableConcept['coding'][0]['code']], \n",
    "                    vocabulary_ids=['LOINC'], \n",
    "                    domain_ids=['Meas Value']\n",
    "                ) if valueCodeableConcept else None\n",
    "\n",
    "                observation = {\n",
    "                    'observation_id': data['id'],\n",
    "                    'person_id': person_id,\n",
    "                    'observation_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[code], \n",
    "                        vocabulary_ids=['LOINC'], \n",
    "                        domain_ids=['Observation'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S'\n",
    "                    ),\n",
    "                    'observation_date': observation_date,\n",
    "                    'observation_datetime': observation_datetime,\n",
    "                    'observation_type_concept_id': 32817,\n",
    "                    'value_as_number': value_as_number,\n",
    "                    'value_as_string': None,\n",
    "                    'value_as_concept_id': value_as_concept_id,\n",
    "                    'qualifier_concept_id': pd.NA,\n",
    "                    'unit_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[valueQuantity['code']] if valueQuantity and 'code' in valueQuantity else None, \n",
    "                        vocabulary_ids=['UCUM'], \n",
    "                        domain_ids=['Unit'], \n",
    "                        invalid_reason=False, \n",
    "                        standard_concept='S'\n",
    "                    ) if valueQuantity and 'code' in valueQuantity else pd.NA,\n",
    "                    'provider_id': pd.NA,\n",
    "                    'visit_occurrence_id': visit_occurrence_id,\n",
    "                    'visit_detail_id': pd.NA,\n",
    "                    'observation_source_value': code,\n",
    "                    'observation_source_concept_id': find_concept_id(\n",
    "                        concept, \n",
    "                        concept_codes=[code], \n",
    "                        vocabulary_ids=['LOINC'], \n",
    "                        domain_ids=['Observation']\n",
    "                    ),\n",
    "                    'unit_source_value': valueQuantity['code'] if valueQuantity and 'code' in valueQuantity else None,\n",
    "                    'qualifier_source_value': None,\n",
    "                    'value_source_value': valueQuantity['value'] if valueQuantity and 'value' in valueQuantity else None,\n",
    "                    'observation_event_id': data['id'],\n",
    "                    'obs_event_field_concept_id': pd.NA\n",
    "                }\n",
    "                observations.append(observation)\n",
    "\n",
    "        elif resource_type == 'Procedure':\n",
    "            person_id = data['subject']['reference'].split('/')[-1]\n",
    "            procedure_code = data['code']['coding'][0]['code']\n",
    "            observation_date = datetime.strptime(data['performedPeriod']['start'].split('T')[0], '%Y-%m-%d').date() if 'performedPeriod' in data and 'start' in data['performedPeriod'] else None\n",
    "            observation_datetime = datetime.fromisoformat(data['performedPeriod']['start']) if 'performedPeriod' in data and 'start' in data['performedPeriod'] else None\n",
    "            visit_occurrence_id = data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None\n",
    "\n",
    "            observation = {\n",
    "                'observation_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'observation_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Observation'], \n",
    "                    invalid_reason=False, \n",
    "                    standard_concept='S'\n",
    "                ),\n",
    "                'observation_date': observation_date,\n",
    "                'observation_datetime': observation_datetime,\n",
    "                'observation_type_concept_id': 32817,\n",
    "                'value_as_number': pd.NA,\n",
    "                'value_as_string': None,\n",
    "                'value_as_concept_id': 0,\n",
    "                'qualifier_concept_id': pd.NA,\n",
    "                'unit_concept_id': 0,\n",
    "                'provider_id': pd.NA,\n",
    "                'visit_occurrence_id': visit_occurrence_id,\n",
    "                'visit_detail_id': pd.NA,\n",
    "                'observation_source_value': procedure_code,\n",
    "                'observation_source_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Observation']\n",
    "                ),\n",
    "                'unit_source_value': None,\n",
    "                'qualifier_source_value': None,\n",
    "                'value_source_value': None,\n",
    "                'observation_event_id': data['id'],\n",
    "                'obs_event_field_concept_id': pd.NA\n",
    "            }\n",
    "            observations.append(observation)\n",
    "\n",
    "        return observations\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                observation_rows.extend(future.result())\n",
    "\n",
    "    observation = pd.DataFrame(observation_rows).drop_duplicates()\n",
    "    observation = observation[observation['observation_source_concept_id'] != 0]\n",
    "\n",
    "    return observation\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/AllergyIntolerance.ndjson', '/workspaces/synthea_dw/data/fhir/CarePlan.ndjson', '/workspaces/synthea_dw/data/fhir/Claim.ndjson', '/workspaces/synthea_dw/data/fhir/Observation.ndjson', '/workspaces/synthea_dw/data/fhir/Procedure.ndjson']\n",
    "observation_df = observation(filepaths, concept)\n",
    "observation_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def death(filepaths, max_workers=10):\n",
    "    death_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "\n",
    "        if 'deceasedDateTime' in data:\n",
    "            person_id = data['id']\n",
    "            death_date = datetime.strptime(data['deceasedDateTime'].split('T')[0], '%Y-%m-%d').date()\n",
    "\n",
    "            return {\n",
    "                'person_id': person_id,\n",
    "                'death_date': death_date,\n",
    "                'death_type_concept_id': 32817,\n",
    "                'cause_concept_id': 0,\n",
    "                'cause_source_value': None,\n",
    "                'cause_source_concept_id': 0\n",
    "            }\n",
    "        return None\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    death_rows.append(result)\n",
    "\n",
    "    death = pd.DataFrame(death_rows).drop_duplicates()\n",
    "\n",
    "    return death\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Patient.ndjson']\n",
    "death_df = death(filepaths)\n",
    "death_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note(filepaths, concept, max_workers=10):\n",
    "    note_rows = []\n",
    "\n",
    "    def process_line(line, resource_type):\n",
    "        data = json.loads(line)\n",
    "        person_id = data['subject']['reference'].split('/')[-1]\n",
    "        provider_id = None\n",
    "        note_text = None\n",
    "        note_title = None\n",
    "        note_date = None\n",
    "        note_datetime = None\n",
    "        note_type_concept_id = 32817\n",
    "        note_class_concept_id = None\n",
    "        note_type_code = None\n",
    "\n",
    "        if resource_type == 'CarePlan':\n",
    "            div_text = data['text']['div']\n",
    "            note_title_end_index = div_text.find('<br/>')\n",
    "            note_title = div_text[len('<div xmlns=\"http://www.w3.org/1999/xhtml\">'):note_title_end_index]\n",
    "            note_text = div_text[note_title_end_index + len('<br/>'):]\n",
    "            note_date = datetime.strptime(data['period']['start'].split('T')[0], '%Y-%m-%d').date()\n",
    "            note_datetime = datetime.fromisoformat(data['period']['start'])\n",
    "            note_class_concept_id = 706300\n",
    "\n",
    "        elif resource_type == 'DiagnosticReport':\n",
    "            provider_id = data['performer'][0]['reference'].split('/')[-1] if 'performer' in data and data['performer'] else None\n",
    "            note_text = data['presentedForm'][0]['data'] if 'presentedForm' in data and data['presentedForm'] else None\n",
    "            note_title = data['code']['coding'][0]['display'] if 'code' in data and 'coding' in data['code'] else None\n",
    "            note_date = datetime.strptime(data['issued'].split('T')[0], '%Y-%m-%d').date()\n",
    "            note_datetime = datetime.fromisoformat(data['issued'])\n",
    "            note_class_concept_id = 42868493\n",
    "\n",
    "        elif resource_type == 'DocumentReference':\n",
    "            provider_id = data['author'][0]['reference'].split('/')[-1] if 'author' in data else None\n",
    "            note_text = data['content'][0]['attachment']['data'] if 'content' in data and 'attachment' in data['content'][0] else None\n",
    "            note_title = data['category'][0]['coding'][0]['display'] if 'category' in data and 'coding' in data['category'][0] else None\n",
    "            note_date = datetime.strptime(data['date'].split('T')[0], '%Y-%m-%d').date()\n",
    "            note_datetime = datetime.fromisoformat(data['date'])\n",
    "            note_type_code = data['type']['coding'][0]['code'] if 'type' in data and 'coding' in data['type'] else None\n",
    "            note_class_concept_id = find_concept_id(concept, concept_codes=[note_type_code], vocabulary_ids=['LOINC'], domain_ids=['Note'], invalid_reason=False, standard_concept='S')\n",
    "\n",
    "        return {\n",
    "            'note_id': data['id'],\n",
    "            'person_id': person_id,\n",
    "            'note_date': note_date,\n",
    "            'note_datetime': note_datetime,\n",
    "            'note_type_concept_id': note_type_concept_id,\n",
    "            'note_class_concept_id': note_class_concept_id,\n",
    "            'note_title': note_title,\n",
    "            'note_text': note_text,\n",
    "            'encoding_concept_id': 32678,\n",
    "            'language_concept_id': 4175745,\n",
    "            'provider_id': provider_id,\n",
    "            'visit_occurrence_id': data['encounter']['reference'].split('/')[-1] if 'encounter' in data else None,\n",
    "            'visit_detail_id': None,\n",
    "            'note_source_value': None,\n",
    "            'note_event_id': None,\n",
    "            'note_event_field_concept_id': None\n",
    "        }\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for filepath in filepaths:\n",
    "            resource_type = filepath.split('/')[-1].split('.')[0]\n",
    "            with open(filepath, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    futures.append(executor.submit(process_line, line, resource_type))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            note_rows.append(future.result())\n",
    "\n",
    "    note = pd.DataFrame(note_rows).drop_duplicates()\n",
    "\n",
    "    return note\n",
    "\n",
    "filepaths = [\n",
    "    '/workspaces/synthea_dw/data/fhir/CarePlan.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/DiagnosticReport.ndjson',\n",
    "    '/workspaces/synthea_dw/data/fhir/DocumentReference.ndjson'\n",
    "]\n",
    "note_df = note(filepaths, concept)\n",
    "note_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(filepaths, max_workers=10):\n",
    "    location_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "\n",
    "        if resource_type == 'Location':\n",
    "            return {\n",
    "                'location_id': data['id'],\n",
    "                'address_1': data['address']['line'][0] if 'address' in data and 'line' in data['address'] and data['address']['line'] else None,\n",
    "                'address_2': None,\n",
    "                'city': data['address']['city'] if 'address' in data and 'city' in data['address'] else None,\n",
    "                'state': data['address']['state'] if 'address' in data and 'state' in data['address'] else None,\n",
    "                'zip': data['address']['postalCode'] if 'address' in data and 'postalCode' in data['address'] else None,\n",
    "                'county': None,\n",
    "                'location_source_value': data['name'] if 'name' in data else None,\n",
    "                'country_concept_id': 42046186 if ('address' in data and 'country' in data['address'] and data['address']['country'] == 'US') else 0,\n",
    "                'country_source_value': data['address']['country'] if 'address' in data and 'country' in data['address'] else None,\n",
    "                'latitude': data['position']['latitude'] if 'position' in data and 'latitude' in data['position'] else None,\n",
    "                'longitude': data['position']['longitude'] if 'position' in data and 'longitude' in data['position'] else None\n",
    "            }\n",
    "\n",
    "        elif resource_type == 'Patient':\n",
    "            address = data['address'][0] if 'address' in data and data['address'] else {}\n",
    "            country_concept_id = 42046186 if address.get('country') == 'US' else 0\n",
    "            latitude, longitude = None, None\n",
    "            if 'extension' in address:\n",
    "                for ext in address['extension']:\n",
    "                    if ext['url'] == 'latitude':\n",
    "                        latitude = ext['valueDecimal']\n",
    "                    elif ext['url'] == 'longitude':\n",
    "                        longitude = ext['valueDecimal']\n",
    "\n",
    "            return {\n",
    "                'location_id': data['id'],\n",
    "                'address_1': address.get('line', [None])[0],\n",
    "                'address_2': None,\n",
    "                'city': address.get('city'),\n",
    "                'state': address.get('state'),\n",
    "                'zip': address.get('postalCode'),\n",
    "                'county': None,\n",
    "                'location_source_value': data['id'],\n",
    "                'country_concept_id': country_concept_id,\n",
    "                'country_source_value': address.get('country'),\n",
    "                'latitude': latitude,\n",
    "                'longitude': longitude\n",
    "            }\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    futures.append(executor.submit(process_line, line))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            location_rows.append(future.result())\n",
    "\n",
    "    location = pd.DataFrame(location_rows).drop_duplicates()\n",
    "\n",
    "    return location\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Location.ndjson', '/workspaces/synthea_dw/data/fhir/Patient.ndjson']\n",
    "location_df = location(filepaths)\n",
    "location_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specimen(filepaths, concept, max_workers=10):\n",
    "    specimen_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "\n",
    "        if resource_type == 'Procedure':\n",
    "            person_id = data['subject']['reference'].split('/')[-1]\n",
    "            procedure_code = data['code']['coding'][0]['code']\n",
    "            specimen_date = datetime.strptime(data['performedPeriod']['start'].split('T')[0], '%Y-%m-%d').date()\n",
    "            specimen_datetime = datetime.fromisoformat(data['performedPeriod']['start'])\n",
    "\n",
    "            return {\n",
    "                'specimen_id': data['id'],\n",
    "                'person_id': person_id,\n",
    "                'specimen_concept_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Specimen'], \n",
    "                    invalid_reason=False, \n",
    "                    standard_concept='S'\n",
    "                ),\n",
    "                'specimen_type_concept_id': 32817,\n",
    "                'specimen_date': specimen_date,\n",
    "                'specimen_datetime': specimen_datetime,\n",
    "                'quantity': 1,\n",
    "                'unit_concept_id': 0,\n",
    "                'anatomic_site_concept_id': 0,\n",
    "                'disease_status_concept_id': 0,\n",
    "                'specimen_source_id': find_concept_id(\n",
    "                    concept, \n",
    "                    concept_codes=[procedure_code], \n",
    "                    vocabulary_ids=['SNOMED'], \n",
    "                    domain_ids=['Specimen']\n",
    "                ),\n",
    "                'specimen_source_value': procedure_code,\n",
    "                'unit_source_value': None,\n",
    "                'anatomic_site_source_value': None,\n",
    "                'disease_status_source_value': None\n",
    "            }\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    futures.append(executor.submit(process_line, line))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                specimen_rows.append(result)\n",
    "\n",
    "    specimen = pd.DataFrame(specimen_rows).drop_duplicates()\n",
    "    specimen = specimen[specimen['specimen_source_id'] != 0]\n",
    "\n",
    "    return specimen\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Procedure.ndjson']\n",
    "specimen_df = specimen(filepaths, concept)\n",
    "specimen_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def care_site(filepaths, max_workers=10):\n",
    "    care_site_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        resource_type = data['resourceType']\n",
    "\n",
    "        if resource_type == 'Organization':\n",
    "            return {\n",
    "                'care_site_id': data['id'],\n",
    "                'care_site_name': data['name'],\n",
    "                'place_of_service_concept_id': 32693,\n",
    "                'location_id': pd.NA,\n",
    "                'care_site_source_value': data['id'],\n",
    "                'place_of_service_source_value': 'Healthcare Provider'\n",
    "            }\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    futures.append(executor.submit(process_line, line))\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                care_site_rows.append(result)\n",
    "\n",
    "    care_site = pd.DataFrame(care_site_rows).drop_duplicates()\n",
    "    \n",
    "    return care_site\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Organization.ndjson']\n",
    "care_site_df = care_site(filepaths)\n",
    "care_site_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provider(filepaths, concept, max_workers=10):\n",
    "    practitioner_file_path, practitioner_role_file_path = filepaths\n",
    "\n",
    "    practitioners_dict = {}\n",
    "    with open(practitioner_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            for identifier in data.get('identifier', []):\n",
    "                if identifier.get('system') == \"http://hl7.org/fhir/sid/us-npi\":\n",
    "                    npi = identifier['value']\n",
    "                    practitioners_dict[npi] = {\n",
    "                        'provider_name': \" \".join(\n",
    "                            data['name'][0].get('prefix', []) +\n",
    "                            data['name'][0].get('given', []) +\n",
    "                            [data['name'][0]['family']]\n",
    "                        ),\n",
    "                        'gender': data['gender']\n",
    "                    }\n",
    "\n",
    "    provider_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        npi = data['practitioner']['identifier']['value']\n",
    "        specialty_code = data['specialty'][0]['coding'][0]['code'] if 'specialty' in data else None\n",
    "\n",
    "        return {\n",
    "            'provider_id': data['id'],\n",
    "            'provider_name': practitioners_dict.get(npi, {}).get('provider_name', ''),\n",
    "            'npi': npi,\n",
    "            'dea': None,\n",
    "            'specialty_concept_id': find_concept_id(concept, concept_codes=[specialty_code], vocabulary_ids=['NUCC'], domain_ids=['Provider'], invalid_reason=False, standard_concept='S'),\n",
    "            'care_site_id': pd.NA,\n",
    "            'year_of_birth': pd.NA,\n",
    "            'gender_concept_id': find_concept_id(concept, concept_names=[practitioners_dict.get(npi, {}).get('gender', '').upper()], vocabulary_ids=['Gender'], domain_ids=['Gender'], invalid_reason=False, standard_concept='S'),\n",
    "            'provider_source_value': data['id'],\n",
    "            'specialty_source_value': specialty_code,\n",
    "            'specialty_source_concept_id': find_concept_id(concept, concept_codes=[specialty_code], vocabulary_ids=['NUCC'], domain_ids=['Provider']),\n",
    "            'gender_source_value': practitioners_dict.get(npi, {}).get('gender', ''),\n",
    "            'gender_source_concept_id': find_concept_id(concept, concept_names=[practitioners_dict.get(npi, {}).get('gender', '').upper()], vocabulary_ids=['Gender'], domain_ids=['Gender'])\n",
    "        }\n",
    "\n",
    "    with open(practitioner_role_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "        for future in as_completed(future_to_line):\n",
    "            provider_rows.append(future.result())\n",
    "\n",
    "    provider = pd.DataFrame(provider_rows).drop_duplicates()\n",
    "\n",
    "    return provider\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Practitioner.ndjson', '/workspaces/synthea_dw/data/fhir/PractitionerRole.ndjson']\n",
    "provider_df = provider(filepaths, concept)\n",
    "provider_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode(filepaths, concept, max_workers=10):\n",
    "    episode_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        episodes = []\n",
    "\n",
    "        if 'reasonCode' in data:\n",
    "            person_id = None\n",
    "            for participant in data.get('participant', []):\n",
    "                for role in participant.get('role', []):\n",
    "                    for coding in role.get('coding', []):\n",
    "                        if coding.get('code') == '116154003':\n",
    "                            person_id = participant['member']['reference'].split('/')[-1]\n",
    "                            break\n",
    "                    if person_id:\n",
    "                        break\n",
    "\n",
    "            if person_id:\n",
    "                for reasonCode in data['reasonCode']:\n",
    "                    for coding in reasonCode.get('coding', []):\n",
    "                        episode = {\n",
    "                            'episode_id': data['id'],\n",
    "                            'person_id': person_id,\n",
    "                            'episode_concept_id': 32533,\n",
    "                            'episode_start_date': datetime.strptime(data['period']['start'].split('T')[0], '%Y-%m-%d').date(),\n",
    "                            'episode_start_datetime': datetime.fromisoformat(data['period']['start']),\n",
    "                            'episode_end_date': None,\n",
    "                            'episode_end_datetime': None,\n",
    "                            'episode_parent_id': pd.NA,\n",
    "                            'episode_number': 1,\n",
    "                            'episode_object_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Condition'],\n",
    "                                invalid_reason=False, \n",
    "                                standard_concept='S'\n",
    "                            ),\n",
    "                            'episode_type_concept_id': 32817,\n",
    "                            'episode_source_value': coding['code'],\n",
    "                            'episode_source_concept_id': find_concept_id(\n",
    "                                concept, \n",
    "                                concept_codes=[coding['code']], \n",
    "                                vocabulary_ids=['SNOMED'], \n",
    "                                domain_ids=['Condition'],\n",
    "                                invalid_reason=True\n",
    "                            ),\n",
    "                        }\n",
    "                        episodes.append(episode)\n",
    "\n",
    "        return episodes\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                episode_rows.extend(future.result())\n",
    "\n",
    "    episode = pd.DataFrame(episode_rows).drop_duplicates()\n",
    "\n",
    "    return episode\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/CareTeam.ndjson']\n",
    "episode_df = episode(filepaths, concept)\n",
    "episode_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(filepaths, max_workers=10):\n",
    "    cost_rows = []\n",
    "\n",
    "    def process_line(line):\n",
    "        data = json.loads(line)\n",
    "        cost = {\n",
    "            'cost_id': data['id'],\n",
    "            'cost_event_id': pd.NA,\n",
    "            'cost_domain_id': 32007,\n",
    "            'cost_type_concept_id': 5032,\n",
    "            'currency_concept_id': 44818668,\n",
    "            'total_charge': pd.NA,\n",
    "            'total_cost': data['total']['value'] if 'total' in data and 'value' in data['total'] else pd.NA,\n",
    "            'total_paid': pd.NA,\n",
    "            'paid_by_payer': pd.NA,\n",
    "            'paid_by_patient': pd.NA,\n",
    "            'paid_patient_copay': pd.NA,\n",
    "            'paid_patient_coinsurance': pd.NA,\n",
    "            'paid_patient_deductible': pd.NA,\n",
    "            'paid_by_primary': pd.NA,\n",
    "            'paid_ingredient_cost': pd.NA,\n",
    "            'paid_dispensing_fee': pd.NA,\n",
    "            'payer_plan_period_id': pd.NA,\n",
    "            'amount_allowed': pd.NA,\n",
    "            'revenue_code_concept_id': 38003025,\n",
    "            'revenue_code_source_value': None,\n",
    "            'drg_concept_id': pd.NA,\n",
    "            'drg_source_value': None\n",
    "        }\n",
    "        return cost\n",
    "\n",
    "    for filepath in filepaths:\n",
    "        with open(filepath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_line = {executor.submit(process_line, line): line for line in lines}\n",
    "\n",
    "            for future in as_completed(future_to_line):\n",
    "                cost_rows.append(future.result())\n",
    "\n",
    "    cost = pd.DataFrame(cost_rows).drop_duplicates()\n",
    "\n",
    "    return cost\n",
    "\n",
    "filepaths = ['/workspaces/synthea_dw/data/fhir/Claim.ndjson']\n",
    "cost_df = cost(filepaths)\n",
    "cost_df.sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
